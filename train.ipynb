{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1aImx2gyr8jD"
      },
      "outputs": [],
      "source": [
        "# Useful libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.cuda import is_available\n",
        "\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hibP_CXqr8jG"
      },
      "outputs": [],
      "source": [
        "# Modified version of LeNet5 from lecture to support 432x288 RGB images\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.name = \"LeNet5\"\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(115920, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class LeNet5m(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5m, self).__init__()\n",
        "        self.name = \"LeNet5\"\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=11, stride=4, padding=2)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(6400, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified version of AlexNet from lecture to support 432x228 RGB images\n",
        "# https://pytorch.org/vision/stable/_modules/torchvision/models/alexnet.html\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.name = \"AlexNet\"\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(256, 384, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 384, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 256, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(6144, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 10)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "5n3GC4X8NKPo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Version with padding\n",
        "\n",
        "class AlexNetP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNetP, self).__init__()\n",
        "        self.name = \"AlexNetP\"\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 256, kernel_size=3 , padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(24576, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 10)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "gXOsHO54APXP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = LeNet5m()\n",
        "params = 0\n",
        "for param in t.parameters():\n",
        "    print(param.numel())\n",
        "    params += param.numel()\n",
        "print(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2edYQgZ-RnM",
        "outputId": "0ca1746f-590a-4ea7-b633-2ff8d195f469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2178\n",
            "6\n",
            "2400\n",
            "16\n",
            "14586240\n",
            "120\n",
            "10080\n",
            "84\n",
            "840\n",
            "10\n",
            "14601974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset in google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lncavUzIuigg",
        "outputId": "bbfdd25d-13c3-4af7-9ade-384d3b89ef46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy zip file from google drive here and extract it\n",
        "# https://stackoverflow.com/questions/3451111/unzipping-files-in-python\n",
        "import os\n",
        "import zipfile\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/APS360/Project/IMData.zip\" \"/content/\"\n",
        "with zipfile.ZipFile(\"IMData.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")"
      ],
      "metadata": {
        "id": "WGgn25wQxaEq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yW_ea0zsr8jH"
      },
      "outputs": [],
      "source": [
        "\"\"\"path = 'dataset/'\n",
        "\n",
        "train_set_features = torchvision.datasets.DatasetFolder(path + 'TrainFeatures', loader=torch.load, extensions=('.tensor'))\n",
        "valid_set_features = torchvision.datasets.DatasetFolder(path + 'ValidFeatures', loader=torch.load, extensions=('.tensor'))\n",
        "test_set_features = torchvision.datasets.DatasetFolder(path + 'TestFeatures', loader=torch.load, extensions=('.tensor'))\n",
        "print(\"train set size: \", len(train_set_features))\n",
        "print(\"validation set size: \", len(valid_set_features))\n",
        "print(\"test set size: \", len(test_set_features))\"\"\"\n",
        "\n",
        "# credit: https://stackoverflow.com/questions/60173417/pytorch-default-dataloader-gets-stuck-for-large-image-classification-training-se\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root: str, folder: str, klass: int, extension: str = \"png\", transform = None):\n",
        "        self._data = pathlib.Path(root) / folder\n",
        "        self.klass = klass\n",
        "        self.extension = extension\n",
        "        self.transform = transform\n",
        "        # Only calculate once how many files are in this folder\n",
        "        # Could be passed as argument if you precalculate it somehow\n",
        "        # e.g. ls | wc -l on Linux\n",
        "        self._length = sum(1 for entry in os.listdir(self._data))\n",
        "\n",
        "    def __len__(self):\n",
        "        # No need to recalculate this value every time\n",
        "        return self._length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # images always follow [0, n-1], so you access them directly\n",
        "        return self.transform(Image.open(self._data / \"{}.{}\".format(str(index), self.extension)).convert('RGB')), self.klass\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "impath = \"/content/IMData\"\n",
        "dataset = (\n",
        "    ImageDataset(impath, \"Arabic\", 0, \"png\", transform)\n",
        "    + ImageDataset(impath, \"English\", 1, \"png\", transform)\n",
        "    + ImageDataset(impath, \"French\", 2, \"png\", transform)\n",
        "    + ImageDataset(impath, \"Hindi\", 3, \"png\", transform)\n",
        "    + ImageDataset(impath, \"Indonesian\", 4, \"png\", transform)\n",
        "    + ImageDataset(impath, \"Japanese\", 5, \"png\", transform)\n",
        "    + ImageDataset(impath, \"Mandarin-CN\", 6, \"png\", transform)\n",
        "    + ImageDataset(impath, \"Portuguese\", 7, \"png\", transform)\n",
        "    + ImageDataset(impath, \"Russian\", 8, \"png\", transform)\n",
        "    + ImageDataset(impath, \"Spanish\", 9, \"png\", transform)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loader(dataset, batch_size):\n",
        "    # Load training data\n",
        "    trainset = dataset\n",
        "\n",
        "    # Get the list of indices to sample from\n",
        "    relevant_indices = list(range(len(trainset)))\n",
        "    \n",
        "    # Split into train and validation\n",
        "    np.random.seed(1000) # Fixed numpy random seed for reproducible shuffling\n",
        "    np.random.shuffle(relevant_indices)\n",
        "    split = int(len(relevant_indices) * 0.6) # split at 60%\n",
        "    split2 = int(len(relevant_indices) * 0.9)\n",
        "    \n",
        "    # Split into training, validation, and testing indices\n",
        "    relevant_train_indices, relevant_val_indices, relevant_test_indices = relevant_indices[:split], relevant_indices[split:split2], relevant_indices[split2:]\n",
        "    print(\"Train: {}, val: {}, test: {}\".format(len(relevant_train_indices), len(relevant_val_indices), len(relevant_test_indices)))\n",
        "    train_sampler = SubsetRandomSampler(relevant_train_indices)\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                               num_workers=2, sampler=train_sampler,\n",
        "                                               pin_memory=True)\n",
        "    val_sampler = SubsetRandomSampler(relevant_val_indices)\n",
        "    val_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                             num_workers=2, sampler=val_sampler,\n",
        "                                             pin_memory=True)\n",
        "    \n",
        "    test_sampler = SubsetRandomSampler(relevant_test_indices)\n",
        "    test_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                              num_workers=2, sampler=test_sampler,\n",
        "                                              pin_memory=True)\n",
        "   \n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "gnO_OEu4uvCd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as lab 2\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path\n",
        "\n",
        "# Same as lab 2 but with different code for calculating error\n",
        "def evaluate(net, loader, criterion):\n",
        "    \"\"\" Evaluate the network on the validation set.\n",
        "\n",
        "     Args:\n",
        "         net: PyTorch neural network object\n",
        "         loader: PyTorch data loader for the validation set\n",
        "         criterion: The loss function\n",
        "     Returns:\n",
        "         err: A scalar for the avg classification error over the validation set\n",
        "         loss: A scalar for the average loss function over the validation set\n",
        "     \"\"\"\n",
        "    total_loss = 0.0\n",
        "    total_err = 0.0\n",
        "    total_epoch = 0\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda(0)\n",
        "            labels = labels.cuda(0)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels.long())\n",
        "\n",
        "        # In this function and train_net I need to use a different method to \n",
        "        # compute the error. The output of the net, when put through a sigmoid\n",
        "        # (which the CrossEntropyLoss function does automatically), returns\n",
        "        # a tensor with a number for each classification. The \"prediction\"\n",
        "        # of the network is the index which corresponds to the highest number\n",
        "        # In order to check the prediction against the label, I find the index\n",
        "        # of the maximum element in each prediction tensor using max\n",
        "        # then simply loop through the result checking them against the \n",
        "        # labels, adding up the number of times the model was incorrect\n",
        "\n",
        "        iz, ix = nn.Sigmoid()(outputs).max(dim=1)\n",
        "        corr = 0\n",
        "        for indx in range(len(ix)):\n",
        "            if ix[indx] != labels[indx]:\n",
        "                corr += 1\n",
        "        total_err += int(corr)\n",
        "        total_loss += loss.item()\n",
        "        total_epoch += len(labels)\n",
        "    err = float(total_err) / total_epoch\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    return err, loss\n",
        "\n",
        "def train_net(dataset, net, batch_size=64, learning_rate=0.01, num_epochs=100):\n",
        "    # Fixed PyTorch random seed for reproducible result\n",
        "    torch.manual_seed(1000)\n",
        "\n",
        "    # Obtain the PyTorch data loader objects to load batches of the datasets\n",
        "    train_loader, val_loader, test_loader = get_data_loader(dataset, batch_size)\n",
        "\n",
        "    # Define the Loss function and optimizer\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    \n",
        "    # Set up some numpy arrays to store the training/test loss/erruracy\n",
        "    train_err = np.zeros(num_epochs)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    val_err = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "    \n",
        "    # Train the network\n",
        "    # Loop over the data iterator and sample a new batch of training data\n",
        "    # Get the output from the network, and optimize our loss function.\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        total_train_loss = 0.0\n",
        "        total_train_err = 0.0\n",
        "        total_epoch = 0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            # Get the inputs\n",
        "            if i % 100 == 0:\n",
        "                print(\"Epoch {}: done {} batches\".format(epoch, i))\n",
        "            inputs, labels = data\n",
        "            if torch.cuda.is_available():\n",
        "                inputs = inputs.cuda(0)\n",
        "                labels = labels.cuda(0)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass, backward pass, and optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # See comment in function evaluate() for more detail on below code\n",
        "            # and how it computes the error\n",
        "            iz, ix = nn.Sigmoid()(outputs).max(dim=1)\n",
        "            corr = 0\n",
        "            for indx in range(len(ix)):\n",
        "                if ix[indx] != labels[indx]:\n",
        "                    corr += 1\n",
        "\n",
        "            total_train_err += int(corr)\n",
        "            total_train_loss += loss.item()\n",
        "            total_epoch += len(labels)\n",
        "        train_err[epoch] = float(total_train_err) / total_epoch\n",
        "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
        "        val_err[epoch], val_loss[epoch] = evaluate(net, val_loader, criterion)\n",
        "        print((\"Epoch {}: Train err: {}, Train loss: {} | \"+\n",
        "               \"Validation err: {}, Validation loss: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_err[epoch],\n",
        "                   train_loss[epoch],\n",
        "                   val_err[epoch],\n",
        "                   val_loss[epoch]))\n",
        "        model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
        "        results_path = \"/content/drive/MyDrive/Colab Notebooks/APS360/Project/Results/\"\n",
        "        torch.save(net.state_dict(), results_path + \"checkpoints/\" + model_path)\n",
        "    print('Finished Training')\n",
        "\n",
        "    # Write the train/test loss/err into CSV file for plotting later\n",
        "    # epochs = np.arange(1, num_epochs + 1)\n",
        "    model_path = get_model_name(net.name, batch_size, learning_rate, num_epochs)\n",
        "    np.savetxt(results_path + \"{}_train_err.csv\".format(model_path), train_err)\n",
        "    np.savetxt(results_path + \"{}_train_loss.csv\".format(model_path), train_loss)\n",
        "    np.savetxt(results_path + \"{}_val_err.csv\".format(model_path), val_err)\n",
        "    np.savetxt(results_path + \"{}_val_loss.csv\".format(model_path), val_loss)"
      ],
      "metadata": {
        "id": "3NOEBFCdu8DP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAEeEuFgr8jK",
        "outputId": "b349a054-ed41-4d90-af17-fe6341512207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 71103, val: 8888, test: 8888\n",
            "Epoch 0: done 0 batches\n",
            "Epoch 0: done 25 batches\n",
            "Epoch 0: done 50 batches\n",
            "Epoch 0: done 75 batches\n",
            "Epoch 0: done 100 batches\n",
            "Epoch 0: done 125 batches\n",
            "Epoch 0: done 150 batches\n",
            "Epoch 0: done 175 batches\n",
            "Epoch 0: done 200 batches\n",
            "Epoch 0: done 225 batches\n",
            "Epoch 0: done 250 batches\n",
            "Epoch 0: done 275 batches\n",
            "Epoch 1: Train err: 0.5396818699632927, Train loss: 1.5467469587171678 | Validation err: 0.3488973897389739, Validation loss: 0.9413445915494646\n",
            "Epoch 1: done 0 batches\n",
            "Epoch 1: done 25 batches\n",
            "Epoch 1: done 50 batches\n",
            "Epoch 1: done 75 batches\n",
            "Epoch 1: done 100 batches\n",
            "Epoch 1: done 125 batches\n",
            "Epoch 1: done 150 batches\n",
            "Epoch 1: done 175 batches\n",
            "Epoch 1: done 200 batches\n",
            "Epoch 1: done 225 batches\n",
            "Epoch 1: done 250 batches\n",
            "Epoch 1: done 275 batches\n",
            "Epoch 2: Train err: 0.2881594306850625, Train loss: 0.7871539408354451 | Validation err: 0.2811656165616562, Validation loss: 0.7449707899774823\n",
            "Epoch 2: done 0 batches\n",
            "Epoch 2: done 25 batches\n",
            "Epoch 2: done 50 batches\n",
            "Epoch 2: done 75 batches\n",
            "Epoch 2: done 100 batches\n",
            "Epoch 2: done 125 batches\n",
            "Epoch 2: done 150 batches\n",
            "Epoch 2: done 175 batches\n",
            "Epoch 2: done 200 batches\n",
            "Epoch 2: done 225 batches\n",
            "Epoch 2: done 250 batches\n",
            "Epoch 2: done 275 batches\n",
            "Epoch 3: Train err: 0.18550553422499755, Train loss: 0.5248584316360007 | Validation err: 0.2274977497749775, Validation loss: 0.6302383056708745\n",
            "Epoch 3: done 0 batches\n",
            "Epoch 3: done 25 batches\n",
            "Epoch 3: done 50 batches\n",
            "Epoch 3: done 75 batches\n",
            "Epoch 3: done 100 batches\n",
            "Epoch 3: done 125 batches\n",
            "Epoch 3: done 150 batches\n",
            "Epoch 3: done 175 batches\n",
            "Epoch 3: done 200 batches\n",
            "Epoch 3: done 225 batches\n",
            "Epoch 3: done 250 batches\n",
            "Epoch 3: done 275 batches\n",
            "Epoch 4: Train err: 0.10179598610466506, Train loss: 0.3077156042559541 | Validation err: 0.20533303330333033, Validation loss: 0.57594347851617\n",
            "Epoch 4: done 0 batches\n",
            "Epoch 4: done 25 batches\n",
            "Epoch 4: done 50 batches\n",
            "Epoch 4: done 75 batches\n",
            "Epoch 4: done 100 batches\n",
            "Epoch 4: done 125 batches\n",
            "Epoch 4: done 150 batches\n",
            "Epoch 4: done 175 batches\n",
            "Epoch 4: done 200 batches\n",
            "Epoch 4: done 225 batches\n",
            "Epoch 4: done 250 batches\n",
            "Epoch 4: done 275 batches\n",
            "Epoch 5: Train err: 0.03611661955191764, Train loss: 0.13232349633848925 | Validation err: 0.18811881188118812, Validation loss: 0.5819982307297843\n",
            "Epoch 5: done 0 batches\n",
            "Epoch 5: done 25 batches\n",
            "Epoch 5: done 50 batches\n",
            "Epoch 5: done 75 batches\n",
            "Epoch 5: done 100 batches\n",
            "Epoch 5: done 125 batches\n",
            "Epoch 5: done 150 batches\n",
            "Epoch 5: done 175 batches\n",
            "Epoch 5: done 200 batches\n",
            "Epoch 5: done 225 batches\n",
            "Epoch 5: done 250 batches\n",
            "Epoch 5: done 275 batches\n",
            "Epoch 6: Train err: 0.0046552184858585435, Train loss: 0.03618655903197879 | Validation err: 0.18193069306930693, Validation loss: 0.598944115638733\n",
            "Epoch 6: done 0 batches\n",
            "Epoch 6: done 25 batches\n",
            "Epoch 6: done 50 batches\n",
            "Epoch 6: done 75 batches\n",
            "Epoch 6: done 100 batches\n",
            "Epoch 6: done 125 batches\n",
            "Epoch 6: done 150 batches\n",
            "Epoch 6: done 175 batches\n",
            "Epoch 6: done 200 batches\n",
            "Epoch 6: done 225 batches\n",
            "Epoch 6: done 250 batches\n",
            "Epoch 6: done 275 batches\n",
            "Epoch 7: Train err: 0.00015470514605572198, Train loss: 0.00908839357045325 | Validation err: 0.17382988298829882, Validation loss: 0.5942223182746342\n",
            "Epoch 7: done 0 batches\n",
            "Epoch 7: done 25 batches\n",
            "Epoch 7: done 50 batches\n",
            "Epoch 7: done 75 batches\n",
            "Epoch 7: done 100 batches\n",
            "Epoch 7: done 125 batches\n",
            "Epoch 7: done 150 batches\n",
            "Epoch 7: done 175 batches\n",
            "Epoch 7: done 200 batches\n",
            "Epoch 7: done 225 batches\n",
            "Epoch 7: done 250 batches\n",
            "Epoch 7: done 275 batches\n",
            "Epoch 8: Train err: 5.625641674753526e-05, Train loss: 0.00449024039746108 | Validation err: 0.17236723672367238, Validation loss: 0.610360073191779\n",
            "Epoch 8: done 0 batches\n",
            "Epoch 8: done 25 batches\n",
            "Epoch 8: done 50 batches\n",
            "Epoch 8: done 75 batches\n",
            "Epoch 8: done 100 batches\n",
            "Epoch 8: done 125 batches\n",
            "Epoch 8: done 150 batches\n",
            "Epoch 8: done 175 batches\n",
            "Epoch 8: done 200 batches\n",
            "Epoch 8: done 225 batches\n",
            "Epoch 8: done 250 batches\n",
            "Epoch 8: done 275 batches\n",
            "Epoch 9: Train err: 5.625641674753526e-05, Train loss: 0.003234331925707809 | Validation err: 0.16842934293429343, Validation loss: 0.6179418299879347\n",
            "Epoch 9: done 0 batches\n",
            "Epoch 9: done 25 batches\n",
            "Epoch 9: done 50 batches\n",
            "Epoch 9: done 75 batches\n",
            "Epoch 9: done 100 batches\n",
            "Epoch 9: done 125 batches\n",
            "Epoch 9: done 150 batches\n",
            "Epoch 9: done 175 batches\n",
            "Epoch 9: done 200 batches\n",
            "Epoch 9: done 225 batches\n",
            "Epoch 9: done 250 batches\n",
            "Epoch 9: done 275 batches\n",
            "Epoch 10: Train err: 2.812820837376763e-05, Train loss: 0.002563711784264113 | Validation err: 0.16932943294329433, Validation loss: 0.6290021044867379\n",
            "Epoch 10: done 0 batches\n",
            "Epoch 10: done 25 batches\n",
            "Epoch 10: done 50 batches\n",
            "Epoch 10: done 75 batches\n",
            "Epoch 10: done 100 batches\n",
            "Epoch 10: done 125 batches\n",
            "Epoch 10: done 150 batches\n",
            "Epoch 10: done 175 batches\n",
            "Epoch 10: done 200 batches\n",
            "Epoch 10: done 225 batches\n",
            "Epoch 10: done 250 batches\n",
            "Epoch 10: done 275 batches\n",
            "Epoch 11: Train err: 2.812820837376763e-05, Train loss: 0.0021085823134840767 | Validation err: 0.16887938793879387, Validation loss: 0.6335680093084063\n",
            "Epoch 11: done 0 batches\n",
            "Epoch 11: done 25 batches\n",
            "Epoch 11: done 50 batches\n",
            "Epoch 11: done 75 batches\n",
            "Epoch 11: done 100 batches\n",
            "Epoch 11: done 125 batches\n",
            "Epoch 11: done 150 batches\n",
            "Epoch 11: done 175 batches\n",
            "Epoch 11: done 200 batches\n",
            "Epoch 11: done 225 batches\n",
            "Epoch 11: done 250 batches\n",
            "Epoch 11: done 275 batches\n",
            "Epoch 12: Train err: 2.812820837376763e-05, Train loss: 0.0018022973517545587 | Validation err: 0.1682043204320432, Validation loss: 0.6408043282372611\n",
            "Epoch 12: done 0 batches\n",
            "Epoch 12: done 25 batches\n",
            "Epoch 12: done 50 batches\n",
            "Epoch 12: done 75 batches\n",
            "Epoch 12: done 100 batches\n",
            "Epoch 12: done 125 batches\n",
            "Epoch 12: done 150 batches\n",
            "Epoch 12: done 175 batches\n",
            "Epoch 12: done 200 batches\n",
            "Epoch 12: done 225 batches\n",
            "Epoch 12: done 250 batches\n",
            "Epoch 12: done 275 batches\n",
            "Epoch 13: Train err: 1.4064104186883816e-05, Train loss: 0.0015629650174854525 | Validation err: 0.16865436543654366, Validation loss: 0.6475599050521851\n",
            "Epoch 13: done 0 batches\n",
            "Epoch 13: done 25 batches\n",
            "Epoch 13: done 50 batches\n",
            "Epoch 13: done 75 batches\n",
            "Epoch 13: done 100 batches\n",
            "Epoch 13: done 125 batches\n",
            "Epoch 13: done 150 batches\n",
            "Epoch 13: done 175 batches\n",
            "Epoch 13: done 200 batches\n",
            "Epoch 13: done 225 batches\n",
            "Epoch 13: done 250 batches\n",
            "Epoch 13: done 275 batches\n",
            "Epoch 14: Train err: 1.4064104186883816e-05, Train loss: 0.0013833710898246562 | Validation err: 0.16865436543654366, Validation loss: 0.6517781410898481\n",
            "Epoch 14: done 0 batches\n",
            "Epoch 14: done 25 batches\n",
            "Epoch 14: done 50 batches\n",
            "Epoch 14: done 75 batches\n",
            "Epoch 14: done 100 batches\n",
            "Epoch 14: done 125 batches\n",
            "Epoch 14: done 150 batches\n",
            "Epoch 14: done 175 batches\n",
            "Epoch 14: done 200 batches\n",
            "Epoch 14: done 225 batches\n",
            "Epoch 14: done 250 batches\n",
            "Epoch 14: done 275 batches\n",
            "Epoch 15: Train err: 1.4064104186883816e-05, Train loss: 0.0012381095843299178 | Validation err: 0.1692169216921692, Validation loss: 0.6574887990951538\n",
            "Epoch 15: done 0 batches\n",
            "Epoch 15: done 25 batches\n",
            "Epoch 15: done 50 batches\n",
            "Epoch 15: done 75 batches\n",
            "Epoch 15: done 100 batches\n",
            "Epoch 15: done 125 batches\n",
            "Epoch 15: done 150 batches\n",
            "Epoch 15: done 175 batches\n",
            "Epoch 15: done 200 batches\n",
            "Epoch 15: done 225 batches\n",
            "Epoch 15: done 250 batches\n",
            "Epoch 15: done 275 batches\n",
            "Epoch 16: Train err: 1.4064104186883816e-05, Train loss: 0.0011214263098173701 | Validation err: 0.16854185418541853, Validation loss: 0.6633237668446132\n",
            "Epoch 16: done 0 batches\n",
            "Epoch 16: done 25 batches\n",
            "Epoch 16: done 50 batches\n",
            "Epoch 16: done 75 batches\n",
            "Epoch 16: done 100 batches\n",
            "Epoch 16: done 125 batches\n",
            "Epoch 16: done 150 batches\n",
            "Epoch 16: done 175 batches\n",
            "Epoch 16: done 200 batches\n",
            "Epoch 16: done 225 batches\n",
            "Epoch 16: done 250 batches\n",
            "Epoch 16: done 275 batches\n",
            "Epoch 17: Train err: 1.4064104186883816e-05, Train loss: 0.0010244453697726666 | Validation err: 0.16955445544554457, Validation loss: 0.665093126467296\n",
            "Epoch 17: done 0 batches\n",
            "Epoch 17: done 25 batches\n",
            "Epoch 17: done 50 batches\n",
            "Epoch 17: done 75 batches\n",
            "Epoch 17: done 100 batches\n",
            "Epoch 17: done 125 batches\n",
            "Epoch 17: done 150 batches\n",
            "Epoch 17: done 175 batches\n",
            "Epoch 17: done 200 batches\n",
            "Epoch 17: done 225 batches\n",
            "Epoch 17: done 250 batches\n",
            "Epoch 17: done 275 batches\n",
            "Epoch 18: Train err: 1.4064104186883816e-05, Train loss: 0.000941252767857124 | Validation err: 0.16865436543654366, Validation loss: 0.6726913486208235\n",
            "Epoch 18: done 0 batches\n",
            "Epoch 18: done 25 batches\n",
            "Epoch 18: done 50 batches\n",
            "Epoch 18: done 75 batches\n",
            "Epoch 18: done 100 batches\n",
            "Epoch 18: done 125 batches\n",
            "Epoch 18: done 150 batches\n",
            "Epoch 18: done 175 batches\n",
            "Epoch 18: done 200 batches\n",
            "Epoch 18: done 225 batches\n",
            "Epoch 18: done 250 batches\n",
            "Epoch 18: done 275 batches\n",
            "Epoch 19: Train err: 1.4064104186883816e-05, Train loss: 0.000870704235468837 | Validation err: 0.16865436543654366, Validation loss: 0.6729273191520146\n",
            "Epoch 19: done 0 batches\n",
            "Epoch 19: done 25 batches\n",
            "Epoch 19: done 50 batches\n",
            "Epoch 19: done 75 batches\n",
            "Epoch 19: done 100 batches\n",
            "Epoch 19: done 125 batches\n",
            "Epoch 19: done 150 batches\n",
            "Epoch 19: done 175 batches\n",
            "Epoch 19: done 200 batches\n",
            "Epoch 19: done 225 batches\n",
            "Epoch 19: done 250 batches\n",
            "Epoch 19: done 275 batches\n",
            "Epoch 20: Train err: 1.4064104186883816e-05, Train loss: 0.000807776689117359 | Validation err: 0.16876687668766877, Validation loss: 0.6786549951348986\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    net = LeNet5()\n",
        "    if torch.cuda.is_available():\n",
        "        net.cuda(0)\n",
        "    train_net(dataset, net, batch_size=256, learning_rate=0.01, num_epochs=20)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    net = AlexNet()\n",
        "    if torch.cuda.is_available():\n",
        "        net.cuda(0)\n",
        "    train_net(dataset, net, batch_size=128, learning_rate=0.05, num_epochs=20)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5KR9tsVe7ek",
        "outputId": "6b48fe89-8853-4ea3-b4fe-5405ef643b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 71103, val: 8888, test: 8888\n",
            "Epoch 0: done 0 batches\n",
            "Epoch 0: done 100 batches\n",
            "Epoch 0: done 200 batches\n",
            "Epoch 0: done 300 batches\n",
            "Epoch 0: done 400 batches\n",
            "Epoch 0: done 500 batches\n",
            "Epoch 1: Train err: 0.8015132976105087, Train loss: 2.174834040857905 | Validation err: 0.7351485148514851, Validation loss: 1.9216315167290823\n",
            "Epoch 1: done 0 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fae6c371710>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fae6c371710>\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "    self._shutdown_workers()\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: done 100 batches\n",
            "Epoch 1: done 200 batches\n",
            "Epoch 1: done 300 batches\n",
            "Epoch 1: done 400 batches\n",
            "Epoch 1: done 500 batches\n",
            "Epoch 2: Train err: 0.5765438870371151, Train loss: 1.3912730056176084 | Validation err: 0.48481098109810983, Validation loss: 1.2298641221863882\n",
            "Epoch 2: done 0 batches\n",
            "Epoch 2: done 100 batches\n",
            "Epoch 2: done 200 batches\n",
            "Epoch 2: done 300 batches\n",
            "Epoch 2: done 400 batches\n",
            "Epoch 2: done 500 batches\n",
            "Epoch 3: Train err: 0.4443694358887811, Train loss: 1.1098462840635999 | Validation err: 0.3885013501350135, Validation loss: 1.0150849282741548\n",
            "Epoch 3: done 0 batches\n",
            "Epoch 3: done 100 batches\n",
            "Epoch 3: done 200 batches\n",
            "Epoch 3: done 300 batches\n",
            "Epoch 3: done 400 batches\n",
            "Epoch 3: done 500 batches\n",
            "Epoch 4: Train err: 0.37546938947723724, Train loss: 0.9439547631165964 | Validation err: 0.3346084608460846, Validation loss: 0.8797412608351026\n",
            "Epoch 4: done 0 batches\n",
            "Epoch 4: done 100 batches\n",
            "Epoch 4: done 200 batches\n",
            "Epoch 4: done 300 batches\n",
            "Epoch 4: done 400 batches\n",
            "Epoch 4: done 500 batches\n",
            "Epoch 5: Train err: 0.312673164282801, Train loss: 0.8056109263528165 | Validation err: 0.3121062106210621, Validation loss: 0.8149701067379542\n",
            "Epoch 5: done 0 batches\n",
            "Epoch 5: done 100 batches\n",
            "Epoch 5: done 200 batches\n",
            "Epoch 5: done 300 batches\n",
            "Epoch 5: done 400 batches\n",
            "Epoch 5: done 500 batches\n",
            "Epoch 6: Train err: 0.2721826083287625, Train loss: 0.6976976512576178 | Validation err: 0.28004050405040504, Validation loss: 0.7398391698087965\n",
            "Epoch 6: done 0 batches\n",
            "Epoch 6: done 100 batches\n",
            "Epoch 6: done 200 batches\n",
            "Epoch 6: done 300 batches\n",
            "Epoch 6: done 400 batches\n",
            "Epoch 6: done 500 batches\n",
            "Epoch 7: Train err: 0.24312616907866053, Train loss: 0.6087704362521926 | Validation err: 0.2646264626462646, Validation loss: 0.6871913326638085\n",
            "Epoch 7: done 0 batches\n",
            "Epoch 7: done 100 batches\n",
            "Epoch 7: done 200 batches\n",
            "Epoch 7: done 300 batches\n",
            "Epoch 7: done 400 batches\n",
            "Epoch 7: done 500 batches\n",
            "Epoch 8: Train err: 0.21827489698043684, Train loss: 0.528818620355438 | Validation err: 0.2509000900090009, Validation loss: 0.6437040656805039\n",
            "Epoch 8: done 0 batches\n",
            "Epoch 8: done 100 batches\n",
            "Epoch 8: done 200 batches\n",
            "Epoch 8: done 300 batches\n",
            "Epoch 8: done 400 batches\n",
            "Epoch 8: done 500 batches\n",
            "Epoch 9: Train err: 0.20226994641576304, Train loss: 0.47210628048871917 | Validation err: 0.2518001800180018, Validation loss: 0.6376975025449481\n",
            "Epoch 9: done 0 batches\n",
            "Epoch 9: done 100 batches\n",
            "Epoch 9: done 200 batches\n",
            "Epoch 9: done 300 batches\n",
            "Epoch 9: done 400 batches\n",
            "Epoch 9: done 500 batches\n",
            "Epoch 10: Train err: 0.19464720194647203, Train loss: 0.42196031692002317 | Validation err: 0.2696894689468947, Validation loss: 0.6584620101111276\n",
            "Epoch 10: done 0 batches\n",
            "Epoch 10: done 100 batches\n",
            "Epoch 10: done 200 batches\n",
            "Epoch 10: done 300 batches\n",
            "Epoch 10: done 400 batches\n",
            "Epoch 10: done 500 batches\n",
            "Epoch 11: Train err: 0.1810190849893816, Train loss: 0.36923949053283217 | Validation err: 0.2608010801080108, Validation loss: 0.6746450360332217\n",
            "Epoch 11: done 0 batches\n",
            "Epoch 11: done 100 batches\n",
            "Epoch 11: done 200 batches\n",
            "Epoch 11: done 300 batches\n",
            "Epoch 11: done 400 batches\n",
            "Epoch 11: done 500 batches\n",
            "Epoch 12: Train err: 0.16955684007707128, Train loss: 0.3386831019850944 | Validation err: 0.2601260126012601, Validation loss: 0.699648545043809\n",
            "Epoch 12: done 0 batches\n",
            "Epoch 12: done 100 batches\n",
            "Epoch 12: done 200 batches\n",
            "Epoch 12: done 300 batches\n",
            "Epoch 12: done 400 batches\n",
            "Epoch 12: done 500 batches\n",
            "Epoch 13: Train err: 0.14474776029140823, Train loss: 0.3058301659716333 | Validation err: 0.247974797479748, Validation loss: 0.6740339692149844\n",
            "Epoch 13: done 0 batches\n",
            "Epoch 13: done 100 batches\n",
            "Epoch 13: done 200 batches\n",
            "Epoch 13: done 300 batches\n",
            "Epoch 13: done 400 batches\n",
            "Epoch 13: done 500 batches\n",
            "Epoch 14: Train err: 0.1579820823312659, Train loss: 0.28558663734429174 | Validation err: 0.25922592259225924, Validation loss: 0.7104444789034979\n",
            "Epoch 14: done 0 batches\n",
            "Epoch 14: done 100 batches\n",
            "Epoch 14: done 200 batches\n",
            "Epoch 14: done 300 batches\n",
            "Epoch 14: done 400 batches\n",
            "Epoch 14: done 500 batches\n",
            "Epoch 15: Train err: 0.16110431346075413, Train loss: 0.27682095680305424 | Validation err: 0.26665166516651667, Validation loss: 0.8172842506851469\n",
            "Epoch 15: done 0 batches\n",
            "Epoch 15: done 100 batches\n",
            "Epoch 15: done 200 batches\n",
            "Epoch 15: done 300 batches\n",
            "Epoch 15: done 400 batches\n",
            "Epoch 15: done 500 batches\n",
            "Epoch 16: Train err: 0.15404413315893845, Train loss: 0.2906495516436349 | Validation err: 0.2481998199819982, Validation loss: 0.7612088748386928\n",
            "Epoch 16: done 0 batches\n",
            "Epoch 16: done 100 batches\n",
            "Epoch 16: done 200 batches\n",
            "Epoch 16: done 300 batches\n",
            "Epoch 16: done 400 batches\n",
            "Epoch 16: done 500 batches\n",
            "Epoch 17: Train err: 0.13915024682502847, Train loss: 0.29387931986678417 | Validation err: 0.25495049504950495, Validation loss: 0.8045456456286567\n",
            "Epoch 17: done 0 batches\n",
            "Epoch 17: done 100 batches\n",
            "Epoch 17: done 200 batches\n",
            "Epoch 17: done 300 batches\n",
            "Epoch 17: done 400 batches\n",
            "Epoch 17: done 500 batches\n",
            "Epoch 18: Train err: 0.15768673614334136, Train loss: 0.31706702870001896 | Validation err: 0.26563906390639064, Validation loss: 0.8454539920602526\n",
            "Epoch 18: done 0 batches\n",
            "Epoch 18: done 100 batches\n",
            "Epoch 18: done 200 batches\n",
            "Epoch 18: done 300 batches\n",
            "Epoch 18: done 400 batches\n",
            "Epoch 18: done 500 batches\n",
            "Epoch 19: Train err: 0.15388942801288272, Train loss: 0.3038523696604178 | Validation err: 0.2708145814581458, Validation loss: 0.8759766267878669\n",
            "Epoch 19: done 0 batches\n",
            "Epoch 19: done 100 batches\n",
            "Epoch 19: done 200 batches\n",
            "Epoch 19: done 300 batches\n",
            "Epoch 19: done 400 batches\n",
            "Epoch 19: done 500 batches\n",
            "Epoch 20: Train err: 0.15823523620662983, Train loss: 0.3093510392597682 | Validation err: 0.3033303330333033, Validation loss: 0.8821881856237139\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    net = AlexNet()\n",
        "    if torch.cuda.is_available():\n",
        "        net.cuda(0)\n",
        "    train_net(dataset, net, batch_size=64, learning_rate=0.02, num_epochs=20)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfAMnwhbcAOQ",
        "outputId": "803895a2-4a50-4d17-94f9-6b36e4bb7a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 71103, val: 8888, test: 8888\n",
            "Epoch 0: done 0 batches\n",
            "Epoch 0: done 100 batches\n",
            "Epoch 0: done 200 batches\n",
            "Epoch 0: done 300 batches\n",
            "Epoch 0: done 400 batches\n",
            "Epoch 0: done 500 batches\n",
            "Epoch 0: done 600 batches\n",
            "Epoch 0: done 700 batches\n",
            "Epoch 0: done 800 batches\n",
            "Epoch 0: done 900 batches\n",
            "Epoch 0: done 1000 batches\n",
            "Epoch 0: done 1100 batches\n",
            "Epoch 1: Train err: 0.7212072627034021, Train loss: 1.805149833969336 | Validation err: 0.5839333933393339, Validation loss: 1.3967356879076511\n",
            "Epoch 1: done 0 batches\n",
            "Epoch 1: done 100 batches\n",
            "Epoch 1: done 200 batches\n",
            "Epoch 1: done 300 batches\n",
            "Epoch 1: done 400 batches\n",
            "Epoch 1: done 500 batches\n",
            "Epoch 1: done 600 batches\n",
            "Epoch 1: done 700 batches\n",
            "Epoch 1: done 800 batches\n",
            "Epoch 1: done 900 batches\n",
            "Epoch 1: done 1000 batches\n",
            "Epoch 1: done 1100 batches\n",
            "Epoch 2: Train err: 0.47872804241733824, Train loss: 1.1976335205868704 | Validation err: 0.4011026102610261, Validation loss: 1.0194779107038923\n",
            "Epoch 2: done 0 batches\n",
            "Epoch 2: done 100 batches\n",
            "Epoch 2: done 200 batches\n",
            "Epoch 2: done 300 batches\n",
            "Epoch 2: done 400 batches\n",
            "Epoch 2: done 500 batches\n",
            "Epoch 2: done 600 batches\n",
            "Epoch 2: done 700 batches\n",
            "Epoch 2: done 800 batches\n",
            "Epoch 2: done 900 batches\n",
            "Epoch 2: done 1000 batches\n",
            "Epoch 2: done 1100 batches\n",
            "Epoch 3: Train err: 0.37541313306048973, Train loss: 0.9730123473007758 | Validation err: 0.332020702070207, Validation loss: 0.8722794248903398\n",
            "Epoch 3: done 0 batches\n",
            "Epoch 3: done 100 batches\n",
            "Epoch 3: done 200 batches\n",
            "Epoch 3: done 300 batches\n",
            "Epoch 3: done 400 batches\n",
            "Epoch 3: done 500 batches\n",
            "Epoch 3: done 600 batches\n",
            "Epoch 3: done 700 batches\n",
            "Epoch 3: done 800 batches\n",
            "Epoch 3: done 900 batches\n",
            "Epoch 3: done 1000 batches\n",
            "Epoch 3: done 1100 batches\n",
            "Epoch 4: Train err: 0.30689281746199176, Train loss: 0.8144986813504024 | Validation err: 0.2779027902790279, Validation loss: 0.7609195499111423\n",
            "Epoch 4: done 0 batches\n",
            "Epoch 4: done 100 batches\n",
            "Epoch 4: done 200 batches\n",
            "Epoch 4: done 300 batches\n",
            "Epoch 4: done 400 batches\n",
            "Epoch 4: done 500 batches\n",
            "Epoch 4: done 600 batches\n",
            "Epoch 4: done 700 batches\n",
            "Epoch 4: done 800 batches\n",
            "Epoch 4: done 900 batches\n",
            "Epoch 4: done 1000 batches\n",
            "Epoch 4: done 1100 batches\n",
            "Epoch 5: Train err: 0.2537867600523185, Train loss: 0.6773118559140326 | Validation err: 0.2606885688568857, Validation loss: 0.6893825513853443\n",
            "Epoch 5: done 0 batches\n",
            "Epoch 5: done 100 batches\n",
            "Epoch 5: done 200 batches\n",
            "Epoch 5: done 300 batches\n",
            "Epoch 5: done 400 batches\n",
            "Epoch 5: done 500 batches\n",
            "Epoch 5: done 600 batches\n",
            "Epoch 5: done 700 batches\n",
            "Epoch 5: done 800 batches\n",
            "Epoch 5: done 900 batches\n",
            "Epoch 5: done 1000 batches\n",
            "Epoch 5: done 1100 batches\n",
            "Epoch 6: Train err: 0.21193198599215224, Train loss: 0.5711436521137866 | Validation err: 0.2842034203420342, Validation loss: 0.7246533850971744\n",
            "Epoch 6: done 0 batches\n",
            "Epoch 6: done 100 batches\n",
            "Epoch 6: done 200 batches\n",
            "Epoch 6: done 300 batches\n",
            "Epoch 6: done 400 batches\n",
            "Epoch 6: done 500 batches\n",
            "Epoch 6: done 600 batches\n",
            "Epoch 6: done 700 batches\n",
            "Epoch 6: done 800 batches\n",
            "Epoch 6: done 900 batches\n",
            "Epoch 6: done 1000 batches\n",
            "Epoch 6: done 1100 batches\n",
            "Epoch 7: Train err: 0.1823129825745749, Train loss: 0.48476220255601954 | Validation err: 0.213996399639964, Validation loss: 0.6232467677524621\n",
            "Epoch 7: done 0 batches\n",
            "Epoch 7: done 100 batches\n",
            "Epoch 7: done 200 batches\n",
            "Epoch 7: done 300 batches\n",
            "Epoch 7: done 400 batches\n",
            "Epoch 7: done 500 batches\n",
            "Epoch 7: done 600 batches\n",
            "Epoch 7: done 700 batches\n",
            "Epoch 7: done 800 batches\n",
            "Epoch 7: done 900 batches\n",
            "Epoch 7: done 1000 batches\n",
            "Epoch 7: done 1100 batches\n",
            "Epoch 8: Train err: 0.15888218499922646, Train loss: 0.4084586442643517 | Validation err: 0.20105760576057605, Validation loss: 0.5932809483233116\n",
            "Epoch 8: done 0 batches\n",
            "Epoch 8: done 100 batches\n",
            "Epoch 8: done 200 batches\n",
            "Epoch 8: done 300 batches\n",
            "Epoch 8: done 400 batches\n",
            "Epoch 8: done 500 batches\n",
            "Epoch 8: done 600 batches\n",
            "Epoch 8: done 700 batches\n",
            "Epoch 8: done 800 batches\n",
            "Epoch 8: done 900 batches\n",
            "Epoch 8: done 1000 batches\n",
            "Epoch 8: done 1100 batches\n",
            "Epoch 9: Train err: 0.13642181061277303, Train loss: 0.3335440220742157 | Validation err: 0.2076957695769577, Validation loss: 0.5780599759422618\n",
            "Epoch 9: done 0 batches\n",
            "Epoch 9: done 100 batches\n",
            "Epoch 9: done 200 batches\n",
            "Epoch 9: done 300 batches\n",
            "Epoch 9: done 400 batches\n",
            "Epoch 9: done 500 batches\n",
            "Epoch 9: done 600 batches\n",
            "Epoch 9: done 700 batches\n",
            "Epoch 9: done 800 batches\n",
            "Epoch 9: done 900 batches\n",
            "Epoch 9: done 1000 batches\n",
            "Epoch 9: done 1100 batches\n",
            "Epoch 10: Train err: 0.126253463285656, Train loss: 0.29339052334722904 | Validation err: 0.20330783078307832, Validation loss: 0.6309551678115516\n",
            "Epoch 10: done 0 batches\n",
            "Epoch 10: done 100 batches\n",
            "Epoch 10: done 200 batches\n",
            "Epoch 10: done 300 batches\n",
            "Epoch 10: done 400 batches\n",
            "Epoch 10: done 500 batches\n",
            "Epoch 10: done 600 batches\n",
            "Epoch 10: done 700 batches\n",
            "Epoch 10: done 800 batches\n",
            "Epoch 10: done 900 batches\n",
            "Epoch 10: done 1000 batches\n",
            "Epoch 10: done 1100 batches\n",
            "Epoch 11: Train err: 0.11968552663038128, Train loss: 0.24500274141826253 | Validation err: 0.2120837083708371, Validation loss: 0.6696324421347474\n",
            "Epoch 11: done 0 batches\n",
            "Epoch 11: done 100 batches\n",
            "Epoch 11: done 200 batches\n",
            "Epoch 11: done 300 batches\n",
            "Epoch 11: done 400 batches\n",
            "Epoch 11: done 500 batches\n",
            "Epoch 11: done 600 batches\n",
            "Epoch 11: done 700 batches\n",
            "Epoch 11: done 800 batches\n",
            "Epoch 11: done 900 batches\n",
            "Epoch 11: done 1000 batches\n",
            "Epoch 11: done 1100 batches\n",
            "Epoch 12: Train err: 0.1066340379449531, Train loss: 0.20742424047685334 | Validation err: 0.22772277227722773, Validation loss: 0.7053674416576358\n",
            "Epoch 12: done 0 batches\n",
            "Epoch 12: done 100 batches\n",
            "Epoch 12: done 200 batches\n",
            "Epoch 12: done 300 batches\n",
            "Epoch 12: done 400 batches\n",
            "Epoch 12: done 500 batches\n",
            "Epoch 12: done 600 batches\n",
            "Epoch 12: done 700 batches\n",
            "Epoch 12: done 800 batches\n",
            "Epoch 12: done 900 batches\n",
            "Epoch 12: done 1000 batches\n",
            "Epoch 12: done 1100 batches\n",
            "Epoch 13: Train err: 0.10363838375314684, Train loss: 0.19787932507874834 | Validation err: 0.22457245724572458, Validation loss: 0.7703486271470571\n",
            "Epoch 13: done 0 batches\n",
            "Epoch 13: done 100 batches\n",
            "Epoch 13: done 200 batches\n",
            "Epoch 13: done 300 batches\n",
            "Epoch 13: done 400 batches\n",
            "Epoch 13: done 500 batches\n",
            "Epoch 13: done 600 batches\n",
            "Epoch 13: done 700 batches\n",
            "Epoch 13: done 800 batches\n",
            "Epoch 13: done 900 batches\n",
            "Epoch 13: done 1000 batches\n",
            "Epoch 13: done 1100 batches\n",
            "Epoch 14: Train err: 0.10195069125072079, Train loss: 0.17834868770122903 | Validation err: 0.2295229522952295, Validation loss: 0.7657518298934689\n",
            "Epoch 14: done 0 batches\n",
            "Epoch 14: done 100 batches\n",
            "Epoch 14: done 200 batches\n",
            "Epoch 14: done 300 batches\n",
            "Epoch 14: done 400 batches\n",
            "Epoch 14: done 500 batches\n",
            "Epoch 14: done 600 batches\n",
            "Epoch 14: done 700 batches\n",
            "Epoch 14: done 800 batches\n",
            "Epoch 14: done 900 batches\n",
            "Epoch 14: done 1000 batches\n",
            "Epoch 14: done 1100 batches\n",
            "Epoch 15: Train err: 0.10851862790599552, Train loss: 0.16600779333997695 | Validation err: 0.25843834383438347, Validation loss: 0.7900014976374536\n",
            "Epoch 15: done 0 batches\n",
            "Epoch 15: done 100 batches\n",
            "Epoch 15: done 200 batches\n",
            "Epoch 15: done 300 batches\n",
            "Epoch 15: done 400 batches\n",
            "Epoch 15: done 500 batches\n",
            "Epoch 15: done 600 batches\n",
            "Epoch 15: done 700 batches\n",
            "Epoch 15: done 800 batches\n",
            "Epoch 15: done 900 batches\n",
            "Epoch 15: done 1000 batches\n",
            "Epoch 15: done 1100 batches\n",
            "Epoch 16: Train err: 0.11083920509683136, Train loss: 0.16507627655568421 | Validation err: 0.25483798379837985, Validation loss: 0.8462622843200355\n",
            "Epoch 16: done 0 batches\n",
            "Epoch 16: done 100 batches\n",
            "Epoch 16: done 200 batches\n",
            "Epoch 16: done 300 batches\n",
            "Epoch 16: done 400 batches\n",
            "Epoch 16: done 500 batches\n",
            "Epoch 16: done 600 batches\n",
            "Epoch 16: done 700 batches\n",
            "Epoch 16: done 800 batches\n",
            "Epoch 16: done 900 batches\n",
            "Epoch 16: done 1000 batches\n",
            "Epoch 16: done 1100 batches\n",
            "Epoch 17: Train err: 0.11307539766254589, Train loss: 0.15771975022473253 | Validation err: 0.2537128712871287, Validation loss: 0.8423984562107127\n",
            "Epoch 17: done 0 batches\n",
            "Epoch 17: done 100 batches\n",
            "Epoch 17: done 200 batches\n",
            "Epoch 17: done 300 batches\n",
            "Epoch 17: done 400 batches\n",
            "Epoch 17: done 500 batches\n",
            "Epoch 17: done 600 batches\n",
            "Epoch 17: done 700 batches\n",
            "Epoch 17: done 800 batches\n",
            "Epoch 17: done 900 batches\n",
            "Epoch 17: done 1000 batches\n",
            "Epoch 17: done 1100 batches\n",
            "Epoch 18: Train err: 0.10806857657201524, Train loss: 0.16460242905778916 | Validation err: 0.23886138613861385, Validation loss: 0.8216216445183583\n",
            "Epoch 18: done 0 batches\n",
            "Epoch 18: done 100 batches\n",
            "Epoch 18: done 200 batches\n",
            "Epoch 18: done 300 batches\n",
            "Epoch 18: done 400 batches\n",
            "Epoch 18: done 500 batches\n",
            "Epoch 18: done 600 batches\n",
            "Epoch 18: done 700 batches\n",
            "Epoch 18: done 800 batches\n",
            "Epoch 18: done 900 batches\n",
            "Epoch 18: done 1000 batches\n",
            "Epoch 18: done 1100 batches\n",
            "Epoch 19: Train err: 0.09739392149417044, Train loss: 0.15324133421959982 | Validation err: 0.24707470747074708, Validation loss: 0.8290172285742039\n",
            "Epoch 19: done 0 batches\n",
            "Epoch 19: done 100 batches\n",
            "Epoch 19: done 200 batches\n",
            "Epoch 19: done 300 batches\n",
            "Epoch 19: done 400 batches\n",
            "Epoch 19: done 500 batches\n",
            "Epoch 19: done 600 batches\n",
            "Epoch 19: done 700 batches\n",
            "Epoch 19: done 800 batches\n",
            "Epoch 19: done 900 batches\n",
            "Epoch 19: done 1000 batches\n",
            "Epoch 19: done 1100 batches\n",
            "Epoch 20: Train err: 0.09601563928385581, Train loss: 0.145265156440068 | Validation err: 0.2436993699369937, Validation loss: 0.9154684395670033\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    net = AlexNet()\n",
        "    if torch.cuda.is_available():\n",
        "        net.cuda(0)\n",
        "    train_net(dataset, net, batch_size=64, learning_rate=0.01, num_epochs=20)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZJmxVokGoqe",
        "outputId": "21a66bac-d869-4d03-fc1e-8ce7d5bdf721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 71103, val: 8888, test: 8888\n",
            "Epoch 0: done 0 batches\n",
            "Epoch 0: done 100 batches\n",
            "Epoch 0: done 200 batches\n",
            "Epoch 0: done 300 batches\n",
            "Epoch 0: done 400 batches\n",
            "Epoch 0: done 500 batches\n",
            "Epoch 0: done 600 batches\n",
            "Epoch 0: done 700 batches\n",
            "Epoch 0: done 800 batches\n",
            "Epoch 0: done 900 batches\n",
            "Epoch 0: done 1000 batches\n",
            "Epoch 0: done 1100 batches\n",
            "Epoch 1: Train err: 0.7606008185308637, Train loss: 1.9437655424020186 | Validation err: 0.6074482448244825, Validation loss: 1.4268805680515098\n",
            "Epoch 1: done 0 batches\n",
            "Epoch 1: done 100 batches\n",
            "Epoch 1: done 200 batches\n",
            "Epoch 1: done 300 batches\n",
            "Epoch 1: done 400 batches\n",
            "Epoch 1: done 500 batches\n",
            "Epoch 1: done 600 batches\n",
            "Epoch 1: done 700 batches\n",
            "Epoch 1: done 800 batches\n",
            "Epoch 1: done 900 batches\n",
            "Epoch 1: done 1000 batches\n",
            "Epoch 1: done 1100 batches\n",
            "Epoch 2: Train err: 0.5164760980549344, Train loss: 1.2723969534428456 | Validation err: 0.439018901890189, Validation loss: 1.1082858396091049\n",
            "Epoch 2: done 0 batches\n",
            "Epoch 2: done 100 batches\n",
            "Epoch 2: done 200 batches\n",
            "Epoch 2: done 300 batches\n",
            "Epoch 2: done 400 batches\n",
            "Epoch 2: done 500 batches\n",
            "Epoch 2: done 600 batches\n",
            "Epoch 2: done 700 batches\n",
            "Epoch 2: done 800 batches\n",
            "Epoch 2: done 900 batches\n",
            "Epoch 2: done 1000 batches\n",
            "Epoch 2: done 1100 batches\n",
            "Epoch 3: Train err: 0.40241621309930664, Train loss: 1.030489349397424 | Validation err: 0.3791629162916292, Validation loss: 0.9724961918035\n",
            "Epoch 3: done 0 batches\n",
            "Epoch 3: done 100 batches\n",
            "Epoch 3: done 200 batches\n",
            "Epoch 3: done 300 batches\n",
            "Epoch 3: done 400 batches\n",
            "Epoch 3: done 500 batches\n",
            "Epoch 3: done 600 batches\n",
            "Epoch 3: done 700 batches\n",
            "Epoch 3: done 800 batches\n",
            "Epoch 3: done 900 batches\n",
            "Epoch 3: done 1000 batches\n",
            "Epoch 3: done 1100 batches\n",
            "Epoch 4: Train err: 0.32299621675597373, Train loss: 0.8550121858783073 | Validation err: 0.2934293429342934, Validation loss: 0.7831652130154397\n",
            "Epoch 4: done 0 batches\n",
            "Epoch 4: done 100 batches\n",
            "Epoch 4: done 200 batches\n",
            "Epoch 4: done 300 batches\n",
            "Epoch 4: done 400 batches\n",
            "Epoch 4: done 500 batches\n",
            "Epoch 4: done 600 batches\n",
            "Epoch 4: done 700 batches\n",
            "Epoch 4: done 800 batches\n",
            "Epoch 4: done 900 batches\n",
            "Epoch 4: done 1000 batches\n",
            "Epoch 4: done 1100 batches\n",
            "Epoch 5: Train err: 0.25893422218471795, Train loss: 0.700434554975168 | Validation err: 0.23582358235823583, Validation loss: 0.6732897546222741\n",
            "Epoch 5: done 0 batches\n",
            "Epoch 5: done 100 batches\n",
            "Epoch 5: done 200 batches\n",
            "Epoch 5: done 300 batches\n",
            "Epoch 5: done 400 batches\n",
            "Epoch 5: done 500 batches\n",
            "Epoch 5: done 600 batches\n",
            "Epoch 5: done 700 batches\n",
            "Epoch 5: done 800 batches\n",
            "Epoch 5: done 900 batches\n",
            "Epoch 5: done 1000 batches\n",
            "Epoch 5: done 1100 batches\n",
            "Epoch 6: Train err: 0.21218513986751614, Train loss: 0.5789055389718468 | Validation err: 0.22997299729972998, Validation loss: 0.6464545006374661\n",
            "Epoch 6: done 0 batches\n",
            "Epoch 6: done 100 batches\n",
            "Epoch 6: done 200 batches\n",
            "Epoch 6: done 300 batches\n",
            "Epoch 6: done 400 batches\n",
            "Epoch 6: done 500 batches\n",
            "Epoch 6: done 600 batches\n",
            "Epoch 6: done 700 batches\n",
            "Epoch 6: done 800 batches\n",
            "Epoch 6: done 900 batches\n",
            "Epoch 6: done 1000 batches\n",
            "Epoch 6: done 1100 batches\n",
            "Epoch 7: Train err: 0.17566066129417887, Train loss: 0.4774819273840297 | Validation err: 0.19509450945094509, Validation loss: 0.5494813200809973\n",
            "Epoch 7: done 0 batches\n",
            "Epoch 7: done 100 batches\n",
            "Epoch 7: done 200 batches\n",
            "Epoch 7: done 300 batches\n",
            "Epoch 7: done 400 batches\n",
            "Epoch 7: done 500 batches\n",
            "Epoch 7: done 600 batches\n",
            "Epoch 7: done 700 batches\n",
            "Epoch 7: done 800 batches\n",
            "Epoch 7: done 900 batches\n",
            "Epoch 7: done 1000 batches\n",
            "Epoch 7: done 1100 batches\n",
            "Epoch 8: Train err: 0.14130205476562172, Train loss: 0.38834409966970973 | Validation err: 0.21028352835283529, Validation loss: 0.6121916491136277\n",
            "Epoch 8: done 0 batches\n",
            "Epoch 8: done 100 batches\n",
            "Epoch 8: done 200 batches\n",
            "Epoch 8: done 300 batches\n",
            "Epoch 8: done 400 batches\n",
            "Epoch 8: done 500 batches\n",
            "Epoch 8: done 600 batches\n",
            "Epoch 8: done 700 batches\n",
            "Epoch 8: done 800 batches\n",
            "Epoch 8: done 900 batches\n",
            "Epoch 8: done 1000 batches\n",
            "Epoch 8: done 1100 batches\n",
            "Epoch 9: Train err: 0.1173227571269848, Train loss: 0.3176895015806791 | Validation err: 0.1833933393339334, Validation loss: 0.5288357433440874\n",
            "Epoch 9: done 0 batches\n",
            "Epoch 9: done 100 batches\n",
            "Epoch 9: done 200 batches\n",
            "Epoch 9: done 300 batches\n",
            "Epoch 9: done 400 batches\n",
            "Epoch 9: done 500 batches\n",
            "Epoch 9: done 600 batches\n",
            "Epoch 9: done 700 batches\n",
            "Epoch 9: done 800 batches\n",
            "Epoch 9: done 900 batches\n",
            "Epoch 9: done 1000 batches\n",
            "Epoch 9: done 1100 batches\n",
            "Epoch 10: Train err: 0.0916838951942956, Train loss: 0.24625448696818253 | Validation err: 0.18283078307830783, Validation loss: 0.5964795488247768\n",
            "Epoch 10: done 0 batches\n",
            "Epoch 10: done 100 batches\n",
            "Epoch 10: done 200 batches\n",
            "Epoch 10: done 300 batches\n",
            "Epoch 10: done 400 batches\n",
            "Epoch 10: done 500 batches\n",
            "Epoch 10: done 600 batches\n",
            "Epoch 10: done 700 batches\n",
            "Epoch 10: done 800 batches\n",
            "Epoch 10: done 900 batches\n",
            "Epoch 10: done 1000 batches\n",
            "Epoch 10: done 1100 batches\n",
            "Epoch 11: Train err: 0.07984191946893943, Train loss: 0.19803940914537754 | Validation err: 0.17022952295229524, Validation loss: 0.549387485753718\n",
            "Epoch 11: done 0 batches\n",
            "Epoch 11: done 100 batches\n",
            "Epoch 11: done 200 batches\n",
            "Epoch 11: done 300 batches\n",
            "Epoch 11: done 400 batches\n",
            "Epoch 11: done 500 batches\n",
            "Epoch 11: done 600 batches\n",
            "Epoch 11: done 700 batches\n",
            "Epoch 11: done 800 batches\n",
            "Epoch 11: done 900 batches\n",
            "Epoch 11: done 1000 batches\n",
            "Epoch 11: done 1100 batches\n",
            "Epoch 12: Train err: 0.06573562296949496, Train loss: 0.15498060387627136 | Validation err: 0.19374437443744374, Validation loss: 0.6476676326861485\n",
            "Epoch 12: done 0 batches\n",
            "Epoch 12: done 100 batches\n",
            "Epoch 12: done 200 batches\n",
            "Epoch 12: done 300 batches\n",
            "Epoch 12: done 400 batches\n",
            "Epoch 12: done 500 batches\n",
            "Epoch 12: done 600 batches\n",
            "Epoch 12: done 700 batches\n",
            "Epoch 12: done 800 batches\n",
            "Epoch 12: done 900 batches\n",
            "Epoch 12: done 1000 batches\n",
            "Epoch 12: done 1100 batches\n",
            "Epoch 13: Train err: 0.058337904167194074, Train loss: 0.11851185558507979 | Validation err: 0.17686768676867687, Validation loss: 0.6485057677939642\n",
            "Epoch 13: done 0 batches\n",
            "Epoch 13: done 100 batches\n",
            "Epoch 13: done 200 batches\n",
            "Epoch 13: done 300 batches\n",
            "Epoch 13: done 400 batches\n",
            "Epoch 13: done 500 batches\n",
            "Epoch 13: done 600 batches\n",
            "Epoch 13: done 700 batches\n",
            "Epoch 13: done 800 batches\n",
            "Epoch 13: done 900 batches\n",
            "Epoch 13: done 1000 batches\n",
            "Epoch 13: done 1100 batches\n",
            "Epoch 14: Train err: 0.056298609060095914, Train loss: 0.10955741425167642 | Validation err: 0.17675517551755177, Validation loss: 0.6650888771890736\n",
            "Epoch 14: done 0 batches\n",
            "Epoch 14: done 100 batches\n",
            "Epoch 14: done 200 batches\n",
            "Epoch 14: done 300 batches\n",
            "Epoch 14: done 400 batches\n",
            "Epoch 14: done 500 batches\n",
            "Epoch 14: done 600 batches\n",
            "Epoch 14: done 700 batches\n",
            "Epoch 14: done 800 batches\n",
            "Epoch 14: done 900 batches\n",
            "Epoch 14: done 1000 batches\n",
            "Epoch 14: done 1100 batches\n",
            "Epoch 15: Train err: 0.0637103919665837, Train loss: 0.08454499435175167 | Validation err: 0.21995949594959496, Validation loss: 0.7056789861308584\n",
            "Epoch 15: done 0 batches\n",
            "Epoch 15: done 100 batches\n",
            "Epoch 15: done 200 batches\n",
            "Epoch 15: done 300 batches\n",
            "Epoch 15: done 400 batches\n",
            "Epoch 15: done 500 batches\n",
            "Epoch 15: done 600 batches\n",
            "Epoch 15: done 700 batches\n",
            "Epoch 15: done 800 batches\n",
            "Epoch 15: done 900 batches\n",
            "Epoch 15: done 1000 batches\n",
            "Epoch 15: done 1100 batches\n",
            "Epoch 16: Train err: 0.062078955880905166, Train loss: 0.08278682247863815 | Validation err: 0.21422142214221424, Validation loss: 0.791847680326846\n",
            "Epoch 16: done 0 batches\n",
            "Epoch 16: done 100 batches\n",
            "Epoch 16: done 200 batches\n",
            "Epoch 16: done 300 batches\n",
            "Epoch 16: done 400 batches\n",
            "Epoch 16: done 500 batches\n",
            "Epoch 16: done 600 batches\n",
            "Epoch 16: done 700 batches\n",
            "Epoch 16: done 800 batches\n",
            "Epoch 16: done 900 batches\n",
            "Epoch 16: done 1000 batches\n",
            "Epoch 16: done 1100 batches\n",
            "Epoch 17: Train err: 0.05485000632884689, Train loss: 0.06815836647911874 | Validation err: 0.18485598559855987, Validation loss: 0.7081250495833459\n",
            "Epoch 17: done 0 batches\n",
            "Epoch 17: done 100 batches\n",
            "Epoch 17: done 200 batches\n",
            "Epoch 17: done 300 batches\n",
            "Epoch 17: done 400 batches\n",
            "Epoch 17: done 500 batches\n",
            "Epoch 17: done 600 batches\n",
            "Epoch 17: done 700 batches\n",
            "Epoch 17: done 800 batches\n",
            "Epoch 17: done 900 batches\n",
            "Epoch 17: done 1000 batches\n",
            "Epoch 17: done 1100 batches\n",
            "Epoch 18: Train err: 0.05769095537459742, Train loss: 0.05782532652074674 | Validation err: 0.20882088208820881, Validation loss: 0.7274205817593088\n",
            "Epoch 18: done 0 batches\n",
            "Epoch 18: done 100 batches\n",
            "Epoch 18: done 200 batches\n",
            "Epoch 18: done 300 batches\n",
            "Epoch 18: done 400 batches\n",
            "Epoch 18: done 500 batches\n",
            "Epoch 18: done 600 batches\n",
            "Epoch 18: done 700 batches\n",
            "Epoch 18: done 800 batches\n",
            "Epoch 18: done 900 batches\n",
            "Epoch 18: done 1000 batches\n",
            "Epoch 18: done 1100 batches\n",
            "Epoch 19: Train err: 0.060574096732908596, Train loss: 0.0549139996075952 | Validation err: 0.20803330333033304, Validation loss: 0.8368023454928569\n",
            "Epoch 19: done 0 batches\n",
            "Epoch 19: done 100 batches\n",
            "Epoch 19: done 200 batches\n",
            "Epoch 19: done 300 batches\n",
            "Epoch 19: done 400 batches\n",
            "Epoch 19: done 500 batches\n",
            "Epoch 19: done 600 batches\n",
            "Epoch 19: done 700 batches\n",
            "Epoch 19: done 800 batches\n",
            "Epoch 19: done 900 batches\n",
            "Epoch 19: done 1000 batches\n",
            "Epoch 19: done 1100 batches\n",
            "Epoch 20: Train err: 0.06427295613405905, Train loss: 0.05068492469753782 | Validation err: 0.18575607560756074, Validation loss: 0.7637307014611128\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    net = LeNet5()\n",
        "    if torch.cuda.is_available():\n",
        "        net.cuda(0)\n",
        "    train_net(dataset, net, batch_size=256, learning_rate=0.001, num_epochs=20)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuFJWIB59HOw",
        "outputId": "cd5058f1-2e2f-4c39-8cb0-f6785b247796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 71103, val: 8888, test: 8888\n",
            "Epoch 0: done 0 batches\n",
            "Epoch 0: done 100 batches\n",
            "Epoch 0: done 200 batches\n",
            "Epoch 1: Train err: 0.7798545771627077, Train loss: 2.1644635826563663 | Validation err: 0.6526777677767777, Validation loss: 1.953768399783543\n",
            "Epoch 1: done 0 batches\n",
            "Epoch 1: done 100 batches\n",
            "Epoch 1: done 200 batches\n",
            "Epoch 2: Train err: 0.6030265952210174, Train loss: 1.8159211758229372 | Validation err: 0.554005400540054, Validation loss: 1.6922163418361118\n",
            "Epoch 2: done 0 batches\n",
            "Epoch 2: done 100 batches\n",
            "Epoch 2: done 200 batches\n",
            "Epoch 3: Train err: 0.49913505759250665, Train loss: 1.5518173489639226 | Validation err: 0.4464446444644464, Validation loss: 1.4428648233413697\n",
            "Epoch 3: done 0 batches\n",
            "Epoch 3: done 100 batches\n",
            "Epoch 3: done 200 batches\n",
            "Epoch 4: Train err: 0.4327102935178544, Train loss: 1.3631587615973657 | Validation err: 0.4173042304230423, Validation loss: 1.2979847294943674\n",
            "Epoch 4: done 0 batches\n",
            "Epoch 4: done 100 batches\n",
            "Epoch 4: done 200 batches\n",
            "Epoch 5: Train err: 0.3579595797645669, Train loss: 1.121900784025947 | Validation err: 0.32279477947794777, Validation loss: 0.9834735666002546\n",
            "Epoch 5: done 0 batches\n",
            "Epoch 5: done 100 batches\n",
            "Epoch 5: done 200 batches\n",
            "Epoch 6: Train err: 0.2903534309382164, Train loss: 0.8625028017613527 | Validation err: 0.29196669666966696, Validation loss: 0.838135312284742\n",
            "Epoch 6: done 0 batches\n",
            "Epoch 6: done 100 batches\n",
            "Epoch 6: done 200 batches\n",
            "Epoch 7: Train err: 0.2540117857193086, Train loss: 0.7516222040859057 | Validation err: 0.2786903690369037, Validation loss: 0.7930288416998726\n",
            "Epoch 7: done 0 batches\n",
            "Epoch 7: done 100 batches\n",
            "Epoch 7: done 200 batches\n",
            "Epoch 8: Train err: 0.23180456520821907, Train loss: 0.6812740609371405 | Validation err: 0.2537128712871287, Validation loss: 0.7284351008278983\n",
            "Epoch 8: done 0 batches\n",
            "Epoch 8: done 100 batches\n",
            "Epoch 8: done 200 batches\n",
            "Epoch 9: Train err: 0.19702403555405537, Train loss: 0.5963336468386136 | Validation err: 0.23593609360936094, Validation loss: 0.6721790501049587\n",
            "Epoch 9: done 0 batches\n",
            "Epoch 9: done 100 batches\n",
            "Epoch 9: done 200 batches\n",
            "Epoch 10: Train err: 0.16914898105565165, Train loss: 0.5235165954708195 | Validation err: 0.23931143114311432, Validation loss: 0.6656917895589556\n",
            "Epoch 10: done 0 batches\n",
            "Epoch 10: done 100 batches\n",
            "Epoch 10: done 200 batches\n",
            "Epoch 11: Train err: 0.14075355470233322, Train loss: 0.4509813320293701 | Validation err: 0.22355985598559855, Validation loss: 0.6263507349150521\n",
            "Epoch 11: done 0 batches\n",
            "Epoch 11: done 100 batches\n",
            "Epoch 11: done 200 batches\n",
            "Epoch 12: Train err: 0.11595853902085707, Train loss: 0.3876954612972067 | Validation err: 0.21680918091809182, Validation loss: 0.6074570553643363\n",
            "Epoch 12: done 0 batches\n",
            "Epoch 12: done 100 batches\n",
            "Epoch 12: done 200 batches\n",
            "Epoch 13: Train err: 0.08830851018944348, Train loss: 0.31820569192762854 | Validation err: 0.21017101710171018, Validation loss: 0.60333879334586\n",
            "Epoch 13: done 0 batches\n",
            "Epoch 13: done 100 batches\n",
            "Epoch 13: done 200 batches\n",
            "Epoch 14: Train err: 0.060939763441767575, Train loss: 0.25057249848576757 | Validation err: 0.21095859585958596, Validation loss: 0.5977975181170873\n",
            "Epoch 14: done 0 batches\n",
            "Epoch 14: done 100 batches\n",
            "Epoch 14: done 200 batches\n",
            "Epoch 15: Train err: 0.04112344064244828, Train loss: 0.1986112748976234 | Validation err: 0.2007200720072007, Validation loss: 0.5670882429395403\n",
            "Epoch 15: done 0 batches\n",
            "Epoch 15: done 100 batches\n",
            "Epoch 15: done 200 batches\n",
            "Epoch 16: Train err: 0.022361925657145267, Train loss: 0.14703831928882669 | Validation err: 0.19925742574257427, Validation loss: 0.5649188194956098\n",
            "Epoch 16: done 0 batches\n",
            "Epoch 16: done 100 batches\n",
            "Epoch 16: done 200 batches\n",
            "Epoch 17: Train err: 0.01035118068154649, Train loss: 0.10553048513561701 | Validation err: 0.19284428442844284, Validation loss: 0.5604539505073003\n",
            "Epoch 17: done 0 batches\n",
            "Epoch 17: done 100 batches\n",
            "Epoch 17: done 200 batches\n",
            "Epoch 18: Train err: 0.004711474902606079, Train loss: 0.07732673000088698 | Validation err: 0.19745724572457246, Validation loss: 0.5732598611286708\n",
            "Epoch 18: done 0 batches\n",
            "Epoch 18: done 100 batches\n",
            "Epoch 18: done 200 batches\n",
            "Epoch 19: Train err: 0.002208064357340759, Train loss: 0.05736364725735976 | Validation err: 0.19273177317731774, Validation loss: 0.5646201755319323\n",
            "Epoch 19: done 0 batches\n",
            "Epoch 19: done 100 batches\n",
            "Epoch 19: done 200 batches\n",
            "Epoch 20: Train err: 0.0009422949805212157, Train loss: 0.04324767789501938 | Validation err: 0.19284428442844284, Validation loss: 0.5717039712837764\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    net = AlexNet()\n",
        "    if torch.cuda.is_available():\n",
        "        net.cuda(0)\n",
        "    train_net(dataset, net, batch_size=64, learning_rate=0.0001, num_epochs=20)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F6r_CQszq-o1",
        "outputId": "4e3d8ca3-d995-466e-cca1-8120ee19dda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 71103, val: 8888, test: 8888\n",
            "Epoch 0: done 0 batches\n",
            "Epoch 0: done 100 batches\n",
            "Epoch 0: done 200 batches\n",
            "Epoch 0: done 300 batches\n",
            "Epoch 0: done 400 batches\n",
            "Epoch 0: done 500 batches\n",
            "Epoch 0: done 600 batches\n",
            "Epoch 0: done 700 batches\n",
            "Epoch 0: done 800 batches\n",
            "Epoch 0: done 900 batches\n",
            "Epoch 0: done 1000 batches\n",
            "Epoch 0: done 1100 batches\n",
            "Epoch 1: Train err: 0.5634783342475002, Train loss: 1.4279102400334218 | Validation err: 0.4383438343834383, Validation loss: 1.1267435863721285\n",
            "Epoch 1: done 0 batches\n",
            "Epoch 1: done 100 batches\n",
            "Epoch 1: done 200 batches\n",
            "Epoch 1: done 300 batches\n",
            "Epoch 1: done 400 batches\n",
            "Epoch 1: done 500 batches\n",
            "Epoch 1: done 600 batches\n",
            "Epoch 1: done 700 batches\n",
            "Epoch 1: done 800 batches\n",
            "Epoch 1: done 900 batches\n",
            "Epoch 1: done 1000 batches\n",
            "Epoch 1: done 1100 batches\n",
            "Epoch 2: Train err: 0.39027889118602593, Train loss: 1.0043201730339297 | Validation err: 0.3402340234023402, Validation loss: 0.8881546280366911\n",
            "Epoch 2: done 0 batches\n",
            "Epoch 2: done 100 batches\n",
            "Epoch 2: done 200 batches\n",
            "Epoch 2: done 300 batches\n",
            "Epoch 2: done 400 batches\n",
            "Epoch 2: done 500 batches\n",
            "Epoch 2: done 600 batches\n",
            "Epoch 2: done 700 batches\n",
            "Epoch 2: done 800 batches\n",
            "Epoch 2: done 900 batches\n",
            "Epoch 2: done 1000 batches\n",
            "Epoch 2: done 1100 batches\n",
            "Epoch 3: Train err: 0.3057114327102935, Train loss: 0.8148942604781699 | Validation err: 0.277002700270027, Validation loss: 0.7419350526744514\n",
            "Epoch 3: done 0 batches\n",
            "Epoch 3: done 100 batches\n",
            "Epoch 3: done 200 batches\n",
            "Epoch 3: done 300 batches\n",
            "Epoch 3: done 400 batches\n",
            "Epoch 3: done 500 batches\n",
            "Epoch 3: done 600 batches\n",
            "Epoch 3: done 700 batches\n",
            "Epoch 3: done 800 batches\n",
            "Epoch 3: done 900 batches\n",
            "Epoch 3: done 1000 batches\n",
            "Epoch 3: done 1100 batches\n",
            "Epoch 4: Train err: 0.2462905925207094, Train loss: 0.6690341839642272 | Validation err: 0.24977497749774977, Validation loss: 0.6767809015812634\n",
            "Epoch 4: done 0 batches\n",
            "Epoch 4: done 100 batches\n",
            "Epoch 4: done 200 batches\n",
            "Epoch 4: done 300 batches\n",
            "Epoch 4: done 400 batches\n",
            "Epoch 4: done 500 batches\n",
            "Epoch 4: done 600 batches\n",
            "Epoch 4: done 700 batches\n",
            "Epoch 4: done 800 batches\n",
            "Epoch 4: done 900 batches\n",
            "Epoch 4: done 1000 batches\n",
            "Epoch 4: done 1100 batches\n",
            "Epoch 5: Train err: 0.20260748491624825, Train loss: 0.5569839224313209 | Validation err: 0.22243474347434744, Validation loss: 0.6287965461504545\n",
            "Epoch 5: done 0 batches\n",
            "Epoch 5: done 100 batches\n",
            "Epoch 5: done 200 batches\n",
            "Epoch 5: done 300 batches\n",
            "Epoch 5: done 400 batches\n",
            "Epoch 5: done 500 batches\n",
            "Epoch 5: done 600 batches\n",
            "Epoch 5: done 700 batches\n",
            "Epoch 5: done 800 batches\n",
            "Epoch 5: done 900 batches\n",
            "Epoch 5: done 1000 batches\n",
            "Epoch 5: done 1100 batches\n",
            "Epoch 6: Train err: 0.16602674992616345, Train loss: 0.459429038619802 | Validation err: 0.21635913591359135, Validation loss: 0.6107292983600562\n",
            "Epoch 6: done 0 batches\n",
            "Epoch 6: done 100 batches\n",
            "Epoch 6: done 200 batches\n",
            "Epoch 6: done 300 batches\n",
            "Epoch 6: done 400 batches\n",
            "Epoch 6: done 500 batches\n",
            "Epoch 6: done 600 batches\n",
            "Epoch 6: done 700 batches\n",
            "Epoch 6: done 800 batches\n",
            "Epoch 6: done 900 batches\n",
            "Epoch 6: done 1000 batches\n",
            "Epoch 6: done 1100 batches\n",
            "Epoch 7: Train err: 0.13358086156702248, Train loss: 0.3721002629487821 | Validation err: 0.1878937893789379, Validation loss: 0.5230810650818639\n",
            "Epoch 7: done 0 batches\n",
            "Epoch 7: done 100 batches\n",
            "Epoch 7: done 200 batches\n",
            "Epoch 7: done 300 batches\n",
            "Epoch 7: done 400 batches\n",
            "Epoch 7: done 500 batches\n",
            "Epoch 7: done 600 batches\n",
            "Epoch 7: done 700 batches\n",
            "Epoch 7: done 800 batches\n",
            "Epoch 7: done 900 batches\n",
            "Epoch 7: done 1000 batches\n",
            "Epoch 7: done 1100 batches\n",
            "Epoch 8: Train err: 0.10794199963433329, Train loss: 0.2988165266791729 | Validation err: 0.18384338433843384, Validation loss: 0.5536083917823627\n",
            "Epoch 8: done 0 batches\n",
            "Epoch 8: done 100 batches\n",
            "Epoch 8: done 200 batches\n",
            "Epoch 8: done 300 batches\n",
            "Epoch 8: done 400 batches\n",
            "Epoch 8: done 500 batches\n",
            "Epoch 8: done 600 batches\n",
            "Epoch 8: done 700 batches\n",
            "Epoch 8: done 800 batches\n",
            "Epoch 8: done 900 batches\n",
            "Epoch 8: done 1000 batches\n",
            "Epoch 8: done 1100 batches\n",
            "Epoch 9: Train err: 0.08231720180583098, Train loss: 0.23216049285969362 | Validation err: 0.16865436543654366, Validation loss: 0.5246600854954273\n",
            "Epoch 9: done 0 batches\n",
            "Epoch 9: done 100 batches\n",
            "Epoch 9: done 200 batches\n",
            "Epoch 9: done 300 batches\n",
            "Epoch 9: done 400 batches\n",
            "Epoch 9: done 500 batches\n",
            "Epoch 9: done 600 batches\n",
            "Epoch 9: done 700 batches\n",
            "Epoch 9: done 800 batches\n",
            "Epoch 9: done 900 batches\n",
            "Epoch 9: done 1000 batches\n",
            "Epoch 9: done 1100 batches\n",
            "Epoch 10: Train err: 0.062149276401839586, Train loss: 0.1738433246588809 | Validation err: 0.1628037803780378, Validation loss: 0.5386773964269556\n",
            "Epoch 10: done 0 batches\n",
            "Epoch 10: done 100 batches\n",
            "Epoch 10: done 200 batches\n",
            "Epoch 10: done 300 batches\n",
            "Epoch 10: done 400 batches\n",
            "Epoch 10: done 500 batches\n",
            "Epoch 10: done 600 batches\n",
            "Epoch 10: done 700 batches\n",
            "Epoch 10: done 800 batches\n",
            "Epoch 10: done 900 batches\n",
            "Epoch 10: done 1000 batches\n",
            "Epoch 10: done 1100 batches\n",
            "Epoch 11: Train err: 0.048042979902395117, Train loss: 0.1331510142222865 | Validation err: 0.1664041404140414, Validation loss: 0.6201867311120891\n",
            "Epoch 11: done 0 batches\n",
            "Epoch 11: done 100 batches\n",
            "Epoch 11: done 200 batches\n",
            "Epoch 11: done 300 batches\n",
            "Epoch 11: done 400 batches\n",
            "Epoch 11: done 500 batches\n",
            "Epoch 11: done 600 batches\n",
            "Epoch 11: done 700 batches\n",
            "Epoch 11: done 800 batches\n",
            "Epoch 11: done 900 batches\n",
            "Epoch 11: done 1000 batches\n",
            "Epoch 11: done 1100 batches\n",
            "Epoch 12: Train err: 0.03711517094918639, Train loss: 0.10531996183087303 | Validation err: 0.1662916291629163, Validation loss: 0.6504106463717042\n",
            "Epoch 12: done 0 batches\n",
            "Epoch 12: done 100 batches\n",
            "Epoch 12: done 200 batches\n",
            "Epoch 12: done 300 batches\n",
            "Epoch 12: done 400 batches\n",
            "Epoch 12: done 500 batches\n",
            "Epoch 12: done 600 batches\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-8898ab2295cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-8898ab2295cf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-df55e4cd10d2>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(dataset, net, batch_size, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mtotal_train_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mtotal_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    net = AlexNetP()\n",
        "    if torch.cuda.is_available():\n",
        "        net.cuda(0)\n",
        "    train_net(dataset, net, batch_size=64, learning_rate=0.0001, num_epochs=30)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZDDmkFKAavZ",
        "outputId": "b7cc37fa-0ef3-4594-f1fb-1fe80cd142ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 53327, val: 26664, test: 8888\n",
            "Epoch 0: done 0 batches\n",
            "Epoch 0: done 100 batches\n",
            "Epoch 0: done 200 batches\n",
            "Epoch 0: done 300 batches\n",
            "Epoch 0: done 400 batches\n",
            "Epoch 0: done 500 batches\n",
            "Epoch 0: done 600 batches\n",
            "Epoch 0: done 700 batches\n",
            "Epoch 0: done 800 batches\n",
            "Epoch 1: Train err: 0.5175427081965983, Train loss: 1.3422637533941428 | Validation err: 0.36603660366036606, Validation loss: 0.9631776488084587\n",
            "Epoch 1: done 0 batches\n",
            "Epoch 1: done 100 batches\n",
            "Epoch 1: done 200 batches\n",
            "Epoch 1: done 300 batches\n",
            "Epoch 1: done 400 batches\n",
            "Epoch 1: done 500 batches\n",
            "Epoch 1: done 600 batches\n",
            "Epoch 1: done 700 batches\n",
            "Epoch 1: done 800 batches\n",
            "Epoch 2: Train err: 0.2777017270800908, Train loss: 0.7364202230025253 | Validation err: 0.23777377737773778, Validation loss: 0.6413958462165128\n",
            "Epoch 2: done 0 batches\n",
            "Epoch 2: done 100 batches\n",
            "Epoch 2: done 200 batches\n",
            "Epoch 2: done 300 batches\n",
            "Epoch 2: done 400 batches\n",
            "Epoch 2: done 500 batches\n",
            "Epoch 2: done 600 batches\n",
            "Epoch 2: done 700 batches\n",
            "Epoch 2: done 800 batches\n",
            "Epoch 3: Train err: 0.1865846569280102, Train loss: 0.5208839006025157 | Validation err: 0.180993099309931, Validation loss: 0.4998250434295737\n",
            "Epoch 3: done 0 batches\n",
            "Epoch 3: done 100 batches\n",
            "Epoch 3: done 200 batches\n",
            "Epoch 3: done 300 batches\n",
            "Epoch 3: done 400 batches\n",
            "Epoch 3: done 500 batches\n",
            "Epoch 3: done 600 batches\n",
            "Epoch 3: done 700 batches\n",
            "Epoch 3: done 800 batches\n",
            "Epoch 4: Train err: 0.13645995461961108, Train loss: 0.380732042147673 | Validation err: 0.16006600660066006, Validation loss: 0.44758100168024606\n",
            "Epoch 4: done 0 batches\n",
            "Epoch 4: done 100 batches\n",
            "Epoch 4: done 200 batches\n",
            "Epoch 4: done 300 batches\n",
            "Epoch 4: done 400 batches\n",
            "Epoch 4: done 500 batches\n",
            "Epoch 4: done 600 batches\n",
            "Epoch 4: done 700 batches\n",
            "Epoch 4: done 800 batches\n",
            "Epoch 5: Train err: 0.10088698032891406, Train loss: 0.2832497837249752 | Validation err: 0.1391014101410141, Validation loss: 0.40298550363353114\n",
            "Epoch 5: done 0 batches\n",
            "Epoch 5: done 100 batches\n",
            "Epoch 5: done 200 batches\n",
            "Epoch 5: done 300 batches\n",
            "Epoch 5: done 400 batches\n",
            "Epoch 5: done 500 batches\n",
            "Epoch 5: done 600 batches\n",
            "Epoch 5: done 700 batches\n",
            "Epoch 5: done 800 batches\n",
            "Epoch 6: Train err: 0.07251486113976034, Train loss: 0.20239993894575453 | Validation err: 0.12522502250225023, Validation loss: 0.3863836790231778\n",
            "Epoch 6: done 0 batches\n",
            "Epoch 6: done 100 batches\n",
            "Epoch 6: done 200 batches\n",
            "Epoch 6: done 300 batches\n",
            "Epoch 6: done 400 batches\n",
            "Epoch 6: done 500 batches\n",
            "Epoch 6: done 600 batches\n",
            "Epoch 6: done 700 batches\n",
            "Epoch 6: done 800 batches\n",
            "Epoch 7: Train err: 0.04873703752320588, Train loss: 0.13732468068702436 | Validation err: 0.1286003600360036, Validation loss: 0.4176770667824671\n",
            "Epoch 7: done 0 batches\n",
            "Epoch 7: done 100 batches\n",
            "Epoch 7: done 200 batches\n",
            "Epoch 7: done 300 batches\n",
            "Epoch 7: done 400 batches\n",
            "Epoch 7: done 500 batches\n",
            "Epoch 7: done 600 batches\n",
            "Epoch 7: done 700 batches\n",
            "Epoch 7: done 800 batches\n",
            "Epoch 8: Train err: 0.034429088454253944, Train loss: 0.09767681463929764 | Validation err: 0.12308730873087309, Validation loss: 0.43723137941148926\n",
            "Epoch 8: done 0 batches\n",
            "Epoch 8: done 100 batches\n",
            "Epoch 8: done 200 batches\n",
            "Epoch 8: done 300 batches\n",
            "Epoch 8: done 400 batches\n",
            "Epoch 8: done 500 batches\n",
            "Epoch 8: done 600 batches\n",
            "Epoch 8: done 700 batches\n",
            "Epoch 8: done 800 batches\n",
            "Epoch 9: Train err: 0.025578037391940294, Train loss: 0.0728545139498486 | Validation err: 0.11813681368136814, Validation loss: 0.4304733622631581\n",
            "Epoch 9: done 0 batches\n",
            "Epoch 9: done 100 batches\n",
            "Epoch 9: done 200 batches\n",
            "Epoch 9: done 300 batches\n",
            "Epoch 9: done 400 batches\n",
            "Epoch 9: done 500 batches\n",
            "Epoch 9: done 600 batches\n",
            "Epoch 9: done 700 batches\n",
            "Epoch 9: done 800 batches\n",
            "Epoch 10: Train err: 0.021696326438764603, Train loss: 0.06106346040323144 | Validation err: 0.1269126912691269, Validation loss: 0.46986515310814053\n",
            "Epoch 10: done 0 batches\n",
            "Epoch 10: done 100 batches\n",
            "Epoch 10: done 200 batches\n",
            "Epoch 10: done 300 batches\n",
            "Epoch 10: done 400 batches\n",
            "Epoch 10: done 500 batches\n",
            "Epoch 10: done 600 batches\n",
            "Epoch 10: done 700 batches\n",
            "Epoch 10: done 800 batches\n",
            "Epoch 11: Train err: 0.015208055956644852, Train loss: 0.0435885473182263 | Validation err: 0.1152115211521152, Validation loss: 0.5119052734449328\n",
            "Epoch 11: done 0 batches\n",
            "Epoch 11: done 100 batches\n",
            "Epoch 11: done 200 batches\n",
            "Epoch 11: done 300 batches\n",
            "Epoch 11: done 400 batches\n",
            "Epoch 11: done 500 batches\n",
            "Epoch 11: done 600 batches\n",
            "Epoch 11: done 700 batches\n",
            "Epoch 11: done 800 batches\n",
            "Epoch 12: Train err: 0.015808127215106795, Train loss: 0.04479745047261723 | Validation err: 0.11592409240924093, Validation loss: 0.5061904911836275\n",
            "Epoch 12: done 0 batches\n",
            "Epoch 12: done 100 batches\n",
            "Epoch 12: done 200 batches\n",
            "Epoch 12: done 300 batches\n",
            "Epoch 12: done 400 batches\n",
            "Epoch 12: done 500 batches\n",
            "Epoch 12: done 600 batches\n",
            "Epoch 12: done 700 batches\n",
            "Epoch 12: done 800 batches\n",
            "Epoch 13: Train err: 0.014814259193279201, Train loss: 0.042138404825258984 | Validation err: 0.1164866486648665, Validation loss: 0.531651479699057\n",
            "Epoch 13: done 0 batches\n",
            "Epoch 13: done 100 batches\n",
            "Epoch 13: done 200 batches\n",
            "Epoch 13: done 300 batches\n",
            "Epoch 13: done 400 batches\n",
            "Epoch 13: done 500 batches\n",
            "Epoch 13: done 600 batches\n",
            "Epoch 13: done 700 batches\n",
            "Epoch 13: done 800 batches\n",
            "Epoch 14: Train err: 0.010745025971834155, Train loss: 0.032542374116333414 | Validation err: 0.121999699969997, Validation loss: 0.6033200528696001\n",
            "Epoch 14: done 0 batches\n",
            "Epoch 14: done 100 batches\n",
            "Epoch 14: done 200 batches\n",
            "Epoch 14: done 300 batches\n",
            "Epoch 14: done 400 batches\n",
            "Epoch 14: done 500 batches\n",
            "Epoch 14: done 600 batches\n",
            "Epoch 14: done 700 batches\n",
            "Epoch 14: done 800 batches\n",
            "Epoch 15: Train err: 0.010219963620679956, Train loss: 0.030093878981999594 | Validation err: 0.11911191119111911, Validation loss: 0.5871517747569142\n",
            "Epoch 15: done 0 batches\n",
            "Epoch 15: done 100 batches\n",
            "Epoch 15: done 200 batches\n",
            "Epoch 15: done 300 batches\n",
            "Epoch 15: done 400 batches\n",
            "Epoch 15: done 500 batches\n",
            "Epoch 15: done 600 batches\n",
            "Epoch 15: done 700 batches\n",
            "Epoch 15: done 800 batches\n",
            "Epoch 16: Train err: 0.011270088322988354, Train loss: 0.0336768342097346 | Validation err: 0.11281128112811281, Validation loss: 0.5592065305321765\n",
            "Epoch 16: done 0 batches\n",
            "Epoch 16: done 100 batches\n",
            "Epoch 16: done 200 batches\n",
            "Epoch 16: done 300 batches\n",
            "Epoch 16: done 400 batches\n",
            "Epoch 16: done 500 batches\n",
            "Epoch 16: done 600 batches\n",
            "Epoch 16: done 700 batches\n",
            "Epoch 16: done 800 batches\n",
            "Epoch 17: Train err: 0.009976184671929792, Train loss: 0.029211877671913362 | Validation err: 0.11993699369936994, Validation loss: 0.5977587716327869\n",
            "Epoch 17: done 0 batches\n",
            "Epoch 17: done 100 batches\n",
            "Epoch 17: done 200 batches\n",
            "Epoch 17: done 300 batches\n",
            "Epoch 17: done 400 batches\n",
            "Epoch 17: done 500 batches\n",
            "Epoch 17: done 600 batches\n",
            "Epoch 17: done 700 batches\n",
            "Epoch 17: done 800 batches\n",
            "Epoch 18: Train err: 0.007744669679524444, Train loss: 0.024222586757344462 | Validation err: 0.11551155115511551, Validation loss: 0.5453974547074567\n",
            "Epoch 18: done 0 batches\n",
            "Epoch 18: done 100 batches\n",
            "Epoch 18: done 200 batches\n",
            "Epoch 18: done 300 batches\n",
            "Epoch 18: done 400 batches\n",
            "Epoch 18: done 500 batches\n",
            "Epoch 18: done 600 batches\n",
            "Epoch 18: done 700 batches\n",
            "Epoch 18: done 800 batches\n",
            "Epoch 19: Train err: 0.01020121139385302, Train loss: 0.02778957855192796 | Validation err: 0.12282478247824782, Validation loss: 0.5684238623300616\n",
            "Epoch 19: done 0 batches\n",
            "Epoch 19: done 100 batches\n",
            "Epoch 19: done 200 batches\n",
            "Epoch 19: done 300 batches\n",
            "Epoch 19: done 400 batches\n",
            "Epoch 19: done 500 batches\n",
            "Epoch 19: done 600 batches\n",
            "Epoch 19: done 700 batches\n",
            "Epoch 19: done 800 batches\n",
            "Epoch 20: Train err: 0.0087197854745251, Train loss: 0.02272508181589602 | Validation err: 0.11423642364236423, Validation loss: 0.6192980973938886\n",
            "Epoch 20: done 0 batches\n",
            "Epoch 20: done 100 batches\n",
            "Epoch 20: done 200 batches\n",
            "Epoch 20: done 300 batches\n",
            "Epoch 20: done 400 batches\n",
            "Epoch 20: done 500 batches\n",
            "Epoch 20: done 600 batches\n",
            "Epoch 20: done 700 batches\n",
            "Epoch 20: done 800 batches\n",
            "Epoch 21: Train err: 0.009076077784236879, Train loss: 0.02248381878514405 | Validation err: 0.11483648364836484, Validation loss: 0.6061094341982755\n",
            "Epoch 21: done 0 batches\n",
            "Epoch 21: done 100 batches\n",
            "Epoch 21: done 200 batches\n",
            "Epoch 21: done 300 batches\n",
            "Epoch 21: done 400 batches\n",
            "Epoch 21: done 500 batches\n",
            "Epoch 21: done 600 batches\n",
            "Epoch 21: done 700 batches\n",
            "Epoch 21: done 800 batches\n",
            "Epoch 22: Train err: 0.007969696401447672, Train loss: 0.02319948068512483 | Validation err: 0.11262376237623763, Validation loss: 0.6196923635774951\n",
            "Epoch 22: done 0 batches\n",
            "Epoch 22: done 100 batches\n",
            "Epoch 22: done 200 batches\n",
            "Epoch 22: done 300 batches\n",
            "Epoch 22: done 400 batches\n",
            "Epoch 22: done 500 batches\n",
            "Epoch 22: done 600 batches\n",
            "Epoch 22: done 700 batches\n",
            "Epoch 22: done 800 batches\n",
            "Epoch 23: Train err: 0.007182102874716372, Train loss: 0.02005879586119222 | Validation err: 0.11453645364536454, Validation loss: 0.626291510727194\n",
            "Epoch 23: done 0 batches\n",
            "Epoch 23: done 100 batches\n",
            "Epoch 23: done 200 batches\n",
            "Epoch 23: done 300 batches\n",
            "Epoch 23: done 400 batches\n",
            "Epoch 23: done 500 batches\n",
            "Epoch 23: done 600 batches\n",
            "Epoch 23: done 700 batches\n",
            "Epoch 23: done 800 batches\n",
            "Epoch 24: Train err: 0.005663172501734581, Train loss: 0.017304821591988744 | Validation err: 0.10696069606960697, Validation loss: 0.5717914220419147\n",
            "Epoch 24: done 0 batches\n",
            "Epoch 24: done 100 batches\n",
            "Epoch 24: done 200 batches\n",
            "Epoch 24: done 300 batches\n",
            "Epoch 24: done 400 batches\n",
            "Epoch 24: done 500 batches\n",
            "Epoch 24: done 600 batches\n",
            "Epoch 24: done 700 batches\n",
            "Epoch 24: done 800 batches\n",
            "Epoch 25: Train err: 0.0063757571211581375, Train loss: 0.020082655521185253 | Validation err: 0.11517401740174017, Validation loss: 0.5785333610159887\n",
            "Epoch 25: done 0 batches\n",
            "Epoch 25: done 100 batches\n",
            "Epoch 25: done 200 batches\n",
            "Epoch 25: done 300 batches\n",
            "Epoch 25: done 400 batches\n",
            "Epoch 25: done 500 batches\n",
            "Epoch 25: done 600 batches\n",
            "Epoch 25: done 700 batches\n",
            "Epoch 25: done 800 batches\n",
            "Epoch 26: Train err: 0.005738181409042324, Train loss: 0.01637124829045747 | Validation err: 0.10377287728772877, Validation loss: 0.5403535788034578\n",
            "Epoch 26: done 0 batches\n",
            "Epoch 26: done 100 batches\n",
            "Epoch 26: done 200 batches\n",
            "Epoch 26: done 300 batches\n",
            "Epoch 26: done 400 batches\n",
            "Epoch 26: done 500 batches\n",
            "Epoch 26: done 600 batches\n",
            "Epoch 26: done 700 batches\n",
            "Epoch 26: done 800 batches\n",
            "Epoch 27: Train err: 0.0067132972040429804, Train loss: 0.01934488434728786 | Validation err: 0.10482298229822982, Validation loss: 0.5058625172175986\n",
            "Epoch 27: done 0 batches\n",
            "Epoch 27: done 100 batches\n",
            "Epoch 27: done 200 batches\n",
            "Epoch 27: done 300 batches\n",
            "Epoch 27: done 400 batches\n",
            "Epoch 27: done 500 batches\n",
            "Epoch 27: done 600 batches\n",
            "Epoch 27: done 700 batches\n",
            "Epoch 27: done 800 batches\n",
            "Epoch 28: Train err: 0.005156862377407317, Train loss: 0.014272595388142833 | Validation err: 0.1077107710771077, Validation loss: 0.5610811101446906\n",
            "Epoch 28: done 0 batches\n",
            "Epoch 28: done 100 batches\n",
            "Epoch 28: done 200 batches\n",
            "Epoch 28: done 300 batches\n",
            "Epoch 28: done 400 batches\n",
            "Epoch 28: done 500 batches\n",
            "Epoch 28: done 600 batches\n",
            "Epoch 28: done 700 batches\n",
            "Epoch 28: done 800 batches\n",
            "Epoch 29: Train err: 0.005138110150580381, Train loss: 0.013270045247695123 | Validation err: 0.11442394239423942, Validation loss: 0.6235196298475174\n",
            "Epoch 29: done 0 batches\n",
            "Epoch 29: done 100 batches\n",
            "Epoch 29: done 200 batches\n",
            "Epoch 29: done 300 batches\n",
            "Epoch 29: done 400 batches\n",
            "Epoch 29: done 500 batches\n",
            "Epoch 29: done 600 batches\n",
            "Epoch 29: done 700 batches\n",
            "Epoch 29: done 800 batches\n",
            "Epoch 30: Train err: 0.0058694469968308734, Train loss: 0.01745982553567925 | Validation err: 0.10737323732373237, Validation loss: 0.6253717262320203\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    net = LeNet5m()\n",
        "    if torch.cuda.is_available():\n",
        "        net.cuda(0)\n",
        "    train_net(dataset, net, batch_size=64, learning_rate=0.001, num_epochs=20)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6Lobmqd8pBSC",
        "outputId": "b6f87d07-40da-4d8b-b3a7-4d553a992459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 53327, val: 26664, test: 8888\n",
            "Epoch 0: done 0 batches\n",
            "Epoch 0: done 100 batches\n",
            "Epoch 0: done 200 batches\n",
            "Epoch 0: done 300 batches\n",
            "Epoch 0: done 400 batches\n",
            "Epoch 0: done 500 batches\n",
            "Epoch 0: done 600 batches\n",
            "Epoch 0: done 700 batches\n",
            "Epoch 0: done 800 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa83e5ff7a0>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa83e5ff7a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train err: 0.4796632100061882, Train loss: 1.306406388465735 | Validation err: 0.3391839183918392, Validation loss: 0.9225179848911094\n",
            "Epoch 1: done 0 batches\n",
            "Epoch 1: done 100 batches\n",
            "Epoch 1: done 200 batches\n",
            "Epoch 1: done 300 batches\n",
            "Epoch 1: done 400 batches\n",
            "Epoch 1: done 500 batches\n",
            "Epoch 1: done 600 batches\n",
            "Epoch 1: done 700 batches\n",
            "Epoch 1: done 800 batches\n",
            "Epoch 2: Train err: 0.29185965833442723, Train loss: 0.7939186100836852 | Validation err: 0.29695469546954695, Validation loss: 0.801548568607806\n",
            "Epoch 2: done 0 batches\n",
            "Epoch 2: done 100 batches\n",
            "Epoch 2: done 200 batches\n",
            "Epoch 2: done 300 batches\n",
            "Epoch 2: done 400 batches\n",
            "Epoch 2: done 500 batches\n",
            "Epoch 2: done 600 batches\n",
            "Epoch 2: done 700 batches\n",
            "Epoch 2: done 800 batches\n",
            "Epoch 3: Train err: 0.2189322482044743, Train loss: 0.606566141370675 | Validation err: 0.27077707770777076, Validation loss: 0.7515194444633502\n",
            "Epoch 3: done 0 batches\n",
            "Epoch 3: done 100 batches\n",
            "Epoch 3: done 200 batches\n",
            "Epoch 3: done 300 batches\n",
            "Epoch 3: done 400 batches\n",
            "Epoch 3: done 500 batches\n",
            "Epoch 3: done 600 batches\n",
            "Epoch 3: done 700 batches\n",
            "Epoch 3: done 800 batches\n",
            "Epoch 4: Train err: 0.15798751101693326, Train loss: 0.4486653735633377 | Validation err: 0.28457845784578456, Validation loss: 0.8231973789578719\n",
            "Epoch 4: done 0 batches\n",
            "Epoch 4: done 100 batches\n",
            "Epoch 4: done 200 batches\n",
            "Epoch 4: done 300 batches\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-1ad501e7159c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-1ad501e7159c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-dbae3a3c9e44>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(dataset, net, batch_size, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mtotal_train_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mtotal_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;31m# Get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curve(path):\n",
        "    \"\"\" Plots the training curve for a model run, given the csv files\n",
        "    containing the train/validation error/loss.\n",
        "\n",
        "    Args:\n",
        "        path: The base path of the csv files produced during training\n",
        "    \"\"\"\n",
        "    train_err = np.loadtxt(\"{}_train_err.csv\".format(path))\n",
        "    val_err = np.loadtxt(\"{}_val_err.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Error\")\n",
        "    n = len(train_err) # number of epochs\n",
        "    plt.plot(range(1,n+1), train_err, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_err, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Error\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "results_path = \"/content/drive/MyDrive/Colab Notebooks/APS360/Project/Results/\"\n",
        "plot_training_curve(results_path + get_model_name(\"AlexNetP\", 64, 0.0001, 30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "dJnMaRaXeUo5",
        "outputId": "bd6eeb5e-6984-4567-dcb5-82767660cddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    test_net = AlexNetP()\n",
        "    results_path = \"/content/drive/MyDrive/Colab Notebooks/APS360/Project/Results/checkpoints/\"\n",
        "    test_net.load_state_dict(torch.load(results_path + get_model_name(\"AlexNetP\", 64, 0.0001, 6)))\n",
        "    train_loader, val_loader, test_loader = get_data_loader(dataset, 64)\n",
        "    if torch.cuda.is_available():\n",
        "        test_net.cuda(0)\n",
        "    test_err, test_loss = evaluate(test_net, test_loader, nn.CrossEntropyLoss())\n",
        "    print(\"Test err: {}, test loss: {}\".format(test_err, test_loss))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shM80ll-Y2zV",
        "outputId": "4fae346c-ec97-421f-c534-5f1df9b813c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 53327, val: 26664, test: 8888\n",
            "Test err: 0.13265076507650764, test loss: 0.4400130833010022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def evaluate_confusion_matrix(net, loader):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda(0)\n",
        "            labels = labels.cuda(0)\n",
        "        outputs = net(inputs)\n",
        "        iz, ix = nn.Sigmoid()(outputs.cpu()).max(dim=1)\n",
        "\n",
        "        y_true.append(labels.cpu())\n",
        "        y_pred.append(ix)\n",
        "\n",
        "    y_true_tensor = torch.cat(y_true)\n",
        "    y_pred_tensor = torch.cat(y_pred)\n",
        "\n",
        "    confusion = confusion_matrix(y_true_tensor, y_pred_tensor)\n",
        "    return confusion\n",
        "\n",
        "def main():\n",
        "    train_loader, val_loader, test_loader = get_data_loader(dataset, 64)\n",
        "    test_net = AlexNetP()\n",
        "    if torch.cuda.is_available():\n",
        "        test_net.cuda(0)\n",
        "    results_path = \"/content/drive/MyDrive/Colab Notebooks/APS360/Project/Results/checkpoints/\"\n",
        "    test_net.load_state_dict(torch.load(results_path + get_model_name(\"AlexNetP\", 64, 0.0001, 6)))\n",
        "    print(evaluate_confusion_matrix(test_net, test_loader))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "sdFBE0eL5WUb",
        "outputId": "6d9b482b-0ab7-4b4d-d12b-9892e8483f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 53327, val: 26664, test: 8888\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2289d46fa361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-2289d46fa361>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mresults_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/APS360/Project/Results/checkpoints/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtest_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mget_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AlexNetP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-2289d46fa361>\u001b[0m in \u001b[0;36mevaluate_confusion_matrix\u001b[0;34m(net, loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langs = [\"Arabic\", \"English\", \"French\", \"Hindi\", \"Indonesian\", \"Japanese\", \"Mandarin-CN\", \"Portuguese\", \"Russian\", \"Spanish\"]\n",
        "def predict(net, file_path):\n",
        "    \n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    im = transform(Image.open(file_path).convert('RGB'))\n",
        "    input = torch.unsqueeze(im, 0)\n",
        "    output = net(input)\n",
        "    print(output)\n",
        "    iz, ix = nn.Sigmoid()(output).max(dim=1)\n",
        "    print(langs[ix[0]])"
      ],
      "metadata": {
        "id": "CAQtkjPSaWuU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_net = AlexNetP()\n",
        "results_path = \"/content/drive/MyDrive/Colab Notebooks/APS360/Project/Results/checkpoints/\"\n",
        "test_net.load_state_dict(torch.load(results_path + get_model_name(\"AlexNetP\", 64, 0.0001, 6)))\n",
        "predict(test_net, \"/content/drive/MyDrive/Colab Notebooks/APS360/Project/aric.png\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQh_v6v5bIcM",
        "outputId": "9019c175-3969-46cb-9d2e-7d0f7b19c582"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -7.2999,  11.9731,   3.4184,  -1.5519, -11.4335, -11.0926,   0.5456,\n",
            "         -12.8109,  -5.6563,  -6.0887]], grad_fn=<AddmmBackward0>)\n",
            "English\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "665ae034104ad7e590537aba2db2bff9dd6ad17aaa8b0473628b6cd4f289ba41"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "trainModel.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}